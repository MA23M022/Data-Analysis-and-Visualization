{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qa2Ery3UDAW6"
      },
      "outputs": [],
      "source": [
        "import numpy as np           #importing libraries.\n",
        "import math as m\n",
        "import pandas as pd\n",
        "import tensorflow as tf\n",
        "import matplotlib.pyplot as plt\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "qck_yYLPDQPk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def cross_entropy(Y, pred_y):          # defining cross entropy cost function. Y and pred_y are actual\n",
        "    r, c = np.shape(pred_y)                     # and predicted labels of a specified dataset.\n",
        "    error = 0\n",
        "    index = np.argmax(Y, axis = 1)\n",
        "    for i in range(r):\n",
        "        error += -np.log(pred_y[i][index[i]])\n",
        "    error = error/r\n",
        "    return error                                 # returning cost value.\n",
        "\n",
        "\n",
        "def sigmoid(z, diff):                 # defining sigmoid function. Where diff represents that this function used for differentiation or not.\n",
        "    val = val = 1/(1 + np.exp(-z))\n",
        "    if(diff == True):\n",
        "        val = val*(1 - val)\n",
        "    return val\n",
        "\n",
        "def softmax(z, diff):         # defining softmax function.\n",
        "    r, c = np.shape(z)\n",
        "    val = np.exp(z)\n",
        "    for i in range(c):\n",
        "        denomenator = np.sum(val[:,i])\n",
        "        val[:,i] = val[:,i]/denomenator\n",
        "    return val\n",
        "\n",
        "def Relu(z, diff):            # defining relu function.\n",
        "    val = np.maximum(0, z)\n",
        "    if(diff == True):\n",
        "        for i in range(val.shape[0]):\n",
        "            for j in range(val.shape[1]):\n",
        "                if(z[i][j] > 0):\n",
        "                    val[i][j] = 1\n",
        "                else:\n",
        "                    val[i][j] = 0\n",
        "    return val\n",
        "\n",
        "\n",
        "\n",
        "def grad_J(y, pred_y, pre_activation, activation_function):   # defining grad_J function to compute gradient of cost function\n",
        "    r, c = np.shape(pred_y)                                     # with respect to optput layer's output.\n",
        "    grad = np.zeros((r, c))\n",
        "\n",
        "    one_hot_vector = np.zeros((r, c))\n",
        "    for j in range(c):\n",
        "        for i in range(r):\n",
        "            if(y[i][j] == 1):\n",
        "                one_hot_vector[i][j] = 1\n",
        "    grad = -(one_hot_vector - pred_y)\n",
        "\n",
        "    return grad                                            # returning gradient.\n",
        "\n",
        "\n",
        "\n",
        "def forward_prop(x, n_layer, f_list, w_list, b_list):   # defining forward propagation algorithm to compute each layer's output.\n",
        "    layer_output_list = []\n",
        "    activation_list = []\n",
        "\n",
        "    h = x\n",
        "    for i in range(n_layer - 1):\n",
        "        active = np.dot(w_list[i], h) + b_list[i]\n",
        "        activation_list.append(active)\n",
        "        output = f_list[i](active, diff = False)\n",
        "        layer_output_list.append(output)\n",
        "        h = output\n",
        "\n",
        "    active = np.dot(w_list[n_layer - 1], h) + b_list[n_layer - 1]\n",
        "    activation_list.append(active)\n",
        "    output = f_list[n_layer - 1](active, diff = False)\n",
        "    layer_output_list.append(output)\n",
        "\n",
        "    return activation_list, layer_output_list    # returning each layer's pre-activation and output vector.\n",
        "\n",
        "\n",
        "\n",
        "def Back_prop(x, y, n_layer, f_list, w_list, b_list, activation_list, layer_output_list):  # defining back propagation algorithm to calculate gradient\n",
        "    r, c = np.shape(x)                              # of cost function with respect to each layer's weight and bias vector.\n",
        "    grad_b_list = []\n",
        "    grad_w_list = []\n",
        "\n",
        "    g = grad_J(y, layer_output_list[n_layer - 1], activation_list[n_layer-1], f_list[n_layer-1])\n",
        "\n",
        "    for k in range((n_layer-1), -1, -1):\n",
        "        grad_b = np.sum(g, axis = 1, keepdims = True)/c\n",
        "        grad_b_list.append(grad_b)\n",
        "\n",
        "        if(k >= 1):\n",
        "            grad_w = np.dot(g, layer_output_list[k-1].T)/c\n",
        "            grad_w_list.append(grad_w)\n",
        "        else:\n",
        "            grad_w = np.dot(g, x.T)/c\n",
        "            grad_w_list.append(grad_w)\n",
        "            break\n",
        "\n",
        "        g = np.dot(w_list[k].T , g)\n",
        "        g = g*(f_list[k-1](activation_list[k-1], diff = True))\n",
        "\n",
        "    grad_b_list = grad_b_list[ : : -1]\n",
        "    grad_w_list = grad_w_list[ : : -1]\n",
        "\n",
        "    return  grad_b_list,  grad_w_list   # returning gradients of cost function with respect to each layer's wight and bias vectors.\n",
        "\n",
        "\n",
        "def calculate_error(X, Y, n_layer, f_list, w_list, b_list):     # This function calculates the error on the entire precified dataset.\n",
        "    a, b = forward_prop(X.T, n_layer, f_list, w_list, b_list)\n",
        "    y_pred = b[n_layer - 1].T\n",
        "    error = cross_entropy(Y, y_pred)\n",
        "    return error\n",
        "\n",
        "\n",
        "def prediction(X, n_layer, f_list, w_list, b_list):        # This function computes the probability of being in each class.\n",
        "    a, b = forward_prop(X.T, n_layer, f_list, w_list, b_list)\n",
        "    y_pred = b[n_layer - 1].T\n",
        "    return y_pred\n",
        "\n",
        "\n",
        "def find_label(y):           # This function finds the predicted labels depending on above prediction.\n",
        "    r, c = np.shape(y)\n",
        "    labeled_y = np.zeros((r, c))\n",
        "    for i in range(r):\n",
        "        temp_max = np.max(y[i])\n",
        "        for j in range(c):\n",
        "            if(y[i][j] == temp_max):\n",
        "                labeled_y[i][j] = 1\n",
        "    return labeled_y\n",
        "\n",
        "\n",
        "def accu(y, labeled_y):     # This function calculates the accuracy between actual and predicted labels.\n",
        "    count = 0\n",
        "    for i in range(y.shape[0]):\n",
        "        if((y[i] == labeled_y[i]).all()):\n",
        "            count += 1\n",
        "\n",
        "    accuracy = count/y.shape[0]\n",
        "    return accuracy\n",
        "\n",
        "\n",
        "\n",
        "def Gradient_descent(X, Y, n_layer, f_list, w_list, b_list, learning_rate, nEpoch):  # This function optimizes the weight and bias vectors.\n",
        "    row, col = np.shape(X)\n",
        "    training_error = []\n",
        "\n",
        "\n",
        "    for epoch in range(nEpoch):\n",
        "        if(epoch % 10 == 0):\n",
        "            err = calculate_error(X, Y, n_layer, f_list, w_list, b_list)\n",
        "            y_train_pred = prediction(X, n_layer, f_list, w_list, b_list)\n",
        "            labeled_y_train = find_label(y_train_pred)\n",
        "            accurate = accu(Y, labeled_y_train)\n",
        "            print(f'At {epoch} -th iteration, training error: {err}, accuracy: {accurate}')\n",
        "            training_error.append(err)\n",
        "\n",
        "        grad_b_list = []\n",
        "        grad_w_list = []\n",
        "\n",
        "        for i in range(n_layer):\n",
        "            mat1 = np.zeros_like(w_list[i], dtype = float)\n",
        "            grad_w_list.append(mat1)\n",
        "\n",
        "            mat2 = np.zeros_like(b_list[i], dtype = float)\n",
        "            grad_b_list.append(mat2)\n",
        "\n",
        "\n",
        "        a, b = forward_prop(X.T, n_layer, f_list, w_list, b_list)     # calling forward propagation.\n",
        "        c, d = Back_prop(X.T, Y.T, n_layer, f_list, w_list, b_list, a, b)    # calling backward propagation.\n",
        "\n",
        "        for k in range(n_layer):\n",
        "            grad_b_list[k] = c[k]\n",
        "            grad_w_list[k] = d[k]\n",
        "\n",
        "        for n in range(n_layer):\n",
        "            b_list[n] -= learning_rate*grad_b_list[n]\n",
        "            w_list[n] -= learning_rate*grad_w_list[n]\n",
        "\n",
        "    return training_error, w_list, b_list   # returning training error , optimize weight and bias vectors of each layers'.\n",
        "\n",
        "\n",
        "def parameter_initialization(x, layer_sizes):   # This function initialize the each layers' weight and bias vectors.\n",
        "    length = len(x)\n",
        "    w_list1 = [np.random.randn(layer_sizes[0], length)/np.sqrt(length)]\n",
        "    w_list2 = [np.random.randn(next_layer, prev_layer)/np.sqrt(prev_layer) for prev_layer, next_layer in zip(layer_sizes[:-1], layer_sizes[1:])]\n",
        "    w_list = w_list1 + w_list2\n",
        "\n",
        "    b_list = [np.random.randn(layer, 1) for layer in layer_sizes]\n",
        "    return w_list, b_list\n",
        "\n"
      ],
      "metadata": {
        "id": "muCycVh0DRmZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "DDvoYSOvPlqV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data = tf.keras.datasets.mnist.load_data() # extracting data from keras library.\n",
        "type(data)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dmPsA3e6PmMV",
        "outputId": "d23f4d8b-4204-4f4f-c5aa-498b42a6f048"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tuple"
            ]
          },
          "metadata": {},
          "execution_count": 37
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "(X_train, y_train), (X_test, y_test) = data   # dividing the entire dataset into train and test dataset.\n",
        "X_train[0].shape\n",
        "X_train.shape\n",
        "\n",
        "y_train.shape\n",
        "print('First five training y labels:')\n",
        "print(y_train[:5])\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pEekSoq4Pmrp",
        "outputId": "f00d09fe-60ac-4f44-d7d2-939f6f479eb5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "First five training y labels:\n",
            "[5 0 4 1 9]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X_train = X_train.reshape((X_train.shape[0], 28*28)).astype('float32') # flatten the 2d picture to one dimenional vector.\n",
        "X_test = X_test.reshape((X_test.shape[0], 28*28)).astype('float32')\n",
        "\n",
        "X_train = X_train/255      # scalling the flattening vector to overcome the overflow.\n",
        "X_test = X_test/255\n",
        "\n",
        "print('The training set looks like:')\n",
        "print(X_train)\n",
        "r, c = np.shape(X_train)\n",
        "print('The shape of training set is:')\n",
        "print(r, c)\n",
        "\n",
        "r1, c1 = np.shape(X_test)\n",
        "print('The shape of testing set is:')\n",
        "print(r1, c1)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "53QnEv2HPpKI",
        "outputId": "bb75ed6a-21ed-4291-8a15-3f5e12883e77"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The training set looks like:\n",
            "[[0. 0. 0. ... 0. 0. 0.]\n",
            " [0. 0. 0. ... 0. 0. 0.]\n",
            " [0. 0. 0. ... 0. 0. 0.]\n",
            " ...\n",
            " [0. 0. 0. ... 0. 0. 0.]\n",
            " [0. 0. 0. ... 0. 0. 0.]\n",
            " [0. 0. 0. ... 0. 0. 0.]]\n",
            "The shape of training set is:\n",
            "60000 784\n",
            "The shape of testing set is:\n",
            "10000 784\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# label vector i.e. y contains 10 categorical values. Therefore, we have to do one hot encoding of y vector.\n",
        "\n",
        "y_train = pd.get_dummies(y_train, dtype = int)\n",
        "y_train = y_train.values\n",
        "print('The traing label is:')\n",
        "print(y_train)\n",
        "r2, c2 = np.shape(y_train)\n",
        "print('The shape of training label is:')\n",
        "print(r2, c2)\n",
        "\n",
        "y_test = pd.get_dummies(y_test, dtype = int)\n",
        "y_test = y_test.values\n",
        "print('The test label is:')\n",
        "print(y_test)\n",
        "r3, c3 = np.shape(y_test)\n",
        "print('The shape of test label is:')\n",
        "print(r3, c3)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VbEmRwDmPpAi",
        "outputId": "5e60f52a-8bfa-4631-c6dc-b5acf055ab33"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The traing label is:\n",
            "[[0 0 0 ... 0 0 0]\n",
            " [1 0 0 ... 0 0 0]\n",
            " [0 0 0 ... 0 0 0]\n",
            " ...\n",
            " [0 0 0 ... 0 0 0]\n",
            " [0 0 0 ... 0 0 0]\n",
            " [0 0 0 ... 0 1 0]]\n",
            "The shape of training label is:\n",
            "60000 10\n",
            "The test label is:\n",
            "[[0 0 0 ... 1 0 0]\n",
            " [0 0 1 ... 0 0 0]\n",
            " [0 1 0 ... 0 0 0]\n",
            " ...\n",
            " [0 0 0 ... 0 0 0]\n",
            " [0 0 0 ... 0 0 0]\n",
            " [0 0 0 ... 0 0 0]]\n",
            "The shape of test label is:\n",
            "10000 10\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# The number of layers in the neural network is 2. The first layer i.e. hidden  layer contains ReLU activation function of size 10. And the second layer i.e. output layer contains softmax function of size 10."
      ],
      "metadata": {
        "id": "KNPBRdRIn3n3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "n_layer = 2\n",
        "layer_sizes = [10, 10]\n",
        "w_list, b_list = parameter_initialization(X_train[0], layer_sizes)\n",
        "\n",
        "f_list = [Relu, softmax]\n",
        "\n",
        "#calling the Gradient Descent algorithm to compute optimal weight vectors.\n",
        "err, list_w, list_b = Gradient_descent(X_train, y_train, n_layer, f_list, w_list, b_list, learning_rate = 0.1, nEpoch = 500)\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "upQWac9UPo3X",
        "outputId": "c1a09c92-99e8-4fd9-fea6-f9ad2718e1bd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "At 0 -th iteration, training error: 3.3973057096555093, accuracy: 0.0993\n",
            "At 10 -th iteration, training error: 2.33108966900554, accuracy: 0.22676666666666667\n",
            "At 20 -th iteration, training error: 1.957508703777053, accuracy: 0.3405666666666667\n",
            "At 30 -th iteration, training error: 1.7397479769495445, accuracy: 0.40603333333333336\n",
            "At 40 -th iteration, training error: 1.581039549418456, accuracy: 0.47428333333333333\n",
            "At 50 -th iteration, training error: 1.4416876379895756, accuracy: 0.5366\n",
            "At 60 -th iteration, training error: 1.3092940503349428, accuracy: 0.5925333333333334\n",
            "At 70 -th iteration, training error: 1.191917627657881, accuracy: 0.6366333333333334\n",
            "At 80 -th iteration, training error: 1.0972040336030848, accuracy: 0.6736166666666666\n",
            "At 90 -th iteration, training error: 1.0200750740703812, accuracy: 0.7002166666666667\n",
            "At 100 -th iteration, training error: 0.956676564627257, accuracy: 0.72065\n",
            "At 110 -th iteration, training error: 0.9039973782766992, accuracy: 0.7371\n",
            "At 120 -th iteration, training error: 0.8597728943888518, accuracy: 0.7509666666666667\n",
            "At 130 -th iteration, training error: 0.8222112627287864, accuracy: 0.7625833333333333\n",
            "At 140 -th iteration, training error: 0.7899368036314225, accuracy: 0.7725166666666666\n",
            "At 150 -th iteration, training error: 0.7619112343433755, accuracy: 0.7815166666666666\n",
            "At 160 -th iteration, training error: 0.7373887447333959, accuracy: 0.7886666666666666\n",
            "At 170 -th iteration, training error: 0.7157576107790904, accuracy: 0.7953666666666667\n",
            "At 180 -th iteration, training error: 0.6965558796548361, accuracy: 0.8011166666666667\n",
            "At 190 -th iteration, training error: 0.679406413079161, accuracy: 0.8064\n",
            "At 200 -th iteration, training error: 0.6639783397678488, accuracy: 0.8103166666666667\n",
            "At 210 -th iteration, training error: 0.6500001923275892, accuracy: 0.8139166666666666\n",
            "At 220 -th iteration, training error: 0.6372645592092615, accuracy: 0.81745\n",
            "At 230 -th iteration, training error: 0.6255789387773711, accuracy: 0.82105\n",
            "At 240 -th iteration, training error: 0.614796689771173, accuracy: 0.8242333333333334\n",
            "At 250 -th iteration, training error: 0.6047906615367762, accuracy: 0.8273666666666667\n",
            "At 260 -th iteration, training error: 0.5954389553485625, accuracy: 0.8298\n",
            "At 270 -th iteration, training error: 0.5866419873881166, accuracy: 0.8325166666666667\n",
            "At 280 -th iteration, training error: 0.5783263577604391, accuracy: 0.8343666666666667\n",
            "At 290 -th iteration, training error: 0.5704271627732047, accuracy: 0.83665\n",
            "At 300 -th iteration, training error: 0.562898951398845, accuracy: 0.8384666666666667\n",
            "At 310 -th iteration, training error: 0.5557031540995905, accuracy: 0.8405\n",
            "At 320 -th iteration, training error: 0.5488096428880496, accuracy: 0.84245\n",
            "At 330 -th iteration, training error: 0.5421959427638434, accuracy: 0.84435\n",
            "At 340 -th iteration, training error: 0.5358390828265827, accuracy: 0.8466166666666667\n",
            "At 350 -th iteration, training error: 0.5297260661792759, accuracy: 0.84855\n",
            "At 360 -th iteration, training error: 0.5238535468769148, accuracy: 0.8503833333333334\n",
            "At 370 -th iteration, training error: 0.5182084064887778, accuracy: 0.8521666666666666\n",
            "At 380 -th iteration, training error: 0.5127725059954125, accuracy: 0.8539833333333333\n",
            "At 390 -th iteration, training error: 0.5075420143399024, accuracy: 0.8552666666666666\n",
            "At 400 -th iteration, training error: 0.5025142753192329, accuracy: 0.8569833333333333\n",
            "At 410 -th iteration, training error: 0.49767974864298453, accuracy: 0.8586666666666667\n",
            "At 420 -th iteration, training error: 0.49303346224209565, accuracy: 0.8601\n",
            "At 430 -th iteration, training error: 0.4885716438740211, accuracy: 0.8611833333333333\n",
            "At 440 -th iteration, training error: 0.4842816323617603, accuracy: 0.8623166666666666\n",
            "At 450 -th iteration, training error: 0.4801581913287382, accuracy: 0.8637166666666667\n",
            "At 460 -th iteration, training error: 0.47619435655994863, accuracy: 0.865\n",
            "At 470 -th iteration, training error: 0.4723817813611544, accuracy: 0.8658166666666667\n",
            "At 480 -th iteration, training error: 0.46871547917120776, accuracy: 0.867\n",
            "At 490 -th iteration, training error: 0.46518416118164113, accuracy: 0.8682333333333333\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "n_iteration1 = len(err)  # array of costs .\n",
        "n_iteration1 = list(i*10 for i in range(1, n_iteration1+1))\n",
        "\n",
        "plt.plot(n_iteration1, err, color = 'red', label = 'loss curve')\n",
        "plt.xlabel('iteration')\n",
        "plt.ylabel('loss')\n",
        "plt.title('loss vs iteration at gradient descent algorithm.')\n",
        "plt.legend(loc = 'upper right')\n",
        "plt.show()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 472
        },
        "id": "_J2uwNhotJrs",
        "outputId": "e2e88b43-4d29-459a-f738-91295caa891b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# predicting probabilities of being in different classes  with the optimal weight vectors.\n",
        "# This is for training dataset.\n",
        "y_train_pred = prediction(X_train, n_layer, f_list, list_w, list_b)   # calling prediction function to compute prediction on training dataset.\n",
        "print(f'The sum of the probabilities of being in different classes of a data sample is: {np.sum(y_train_pred[0])}')\n",
        "print('The prediction of probabilities of being in different classes of each data sample is:')\n",
        "print(y_train_pred)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "htM0rX46PovI",
        "outputId": "a59fe7fe-7092-4bfb-fba4-45c921b23855"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The sum of the probabilities of being in different classes of a data sample is: 1.0000000000000002\n",
            "The prediction of probabilities of being in different classes of each data sample is:\n",
            "[[9.40596184e-02 7.75657275e-04 2.27260758e-02 ... 4.92881921e-03\n",
            "  1.67940176e-01 1.53348229e-02]\n",
            " [9.97372980e-01 1.09757281e-07 5.17884451e-05 ... 3.87923998e-06\n",
            "  7.46765394e-06 2.56920945e-05]\n",
            " [6.72425644e-03 2.30685632e-04 1.76257269e-02 ... 1.59938854e-03\n",
            "  1.10421892e-02 3.07041028e-01]\n",
            " ...\n",
            " [1.72113660e-03 1.83489342e-05 1.01209541e-06 ... 2.91954547e-04\n",
            "  9.96419471e-02 2.98160068e-02]\n",
            " [4.83635437e-02 3.78618477e-04 4.60281950e-02 ... 3.32328003e-04\n",
            "  7.09174373e-03 5.93843609e-02]\n",
            " [3.28765605e-02 4.80377645e-03 2.37923438e-02 ... 1.13478218e-02\n",
            "  3.17505342e-01 1.03423207e-01]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# finding label based on predicted value.\n",
        "\n",
        "labeled_y_train = find_label(y_train_pred)    # calling find_label function to find corresponding label.\n",
        "print(f'The predicted label for training dataset is:')\n",
        "print(labeled_y_train)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2TIXBVgqb136",
        "outputId": "c76ced35-0059-43a6-9334-d88c4c435e65"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The predicted label for training dataset is:\n",
            "[[0. 0. 0. ... 0. 0. 0.]\n",
            " [1. 0. 0. ... 0. 0. 0.]\n",
            " [0. 0. 0. ... 0. 0. 0.]\n",
            " ...\n",
            " [0. 0. 0. ... 0. 0. 0.]\n",
            " [0. 0. 0. ... 0. 0. 0.]\n",
            " [0. 0. 0. ... 0. 1. 0.]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#printing the actual label of training dataset.\n",
        "\n",
        "print('The actual label of training dataset:')\n",
        "print(y_train)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "E9x8jf4Gb1sp",
        "outputId": "2ffdaee7-3351-487d-cf16-9744dc39c910"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The actual label of training dataset:\n",
            "[[0 0 0 ... 0 0 0]\n",
            " [1 0 0 ... 0 0 0]\n",
            " [0 0 0 ... 0 0 0]\n",
            " ...\n",
            " [0 0 0 ... 0 0 0]\n",
            " [0 0 0 ... 0 0 0]\n",
            " [0 0 0 ... 0 1 0]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "accurate1 = accu(y_train, labeled_y_train)   # calling accuracy function to compute accuracy\n",
        "print(f'The training accuracy is: {accurate1}')      # predicted label and actual lebel.\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZRpIKi92b1gw",
        "outputId": "2b2b7a1f-1f22-4621-e566-1a7f64629ddb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The training accuracy is: 0.8689\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# predicting probabilities of being in different classes  with the optimal weight vectors.\n",
        "# This is for testing dataset.\n",
        "\n",
        "y_pred = prediction(X_test, n_layer, f_list, list_w, list_b)  # calling prediction function to compute prediction on testing dataset.\n",
        "print(f'The sum of the probabilities of being in different classes of a data sample is: {np.sum(y_pred[0])}')\n",
        "print('The prediction of probabilities of being in different classes of each data sample is:')\n",
        "print(y_pred)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RflMVEZtb1Vi",
        "outputId": "8144d6ea-4cf0-4f06-86dc-c735bfadb5f2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The sum of the probabilities of being in different classes of a data sample is: 0.9999999999999999\n",
            "The prediction of probabilities of being in different classes of each data sample is:\n",
            "[[4.29081271e-04 1.78012832e-06 4.86078218e-05 ... 9.73059546e-01\n",
            "  1.84421675e-05 2.50369055e-02]\n",
            " [1.34470483e-03 1.08983946e-04 9.86507062e-01 ... 1.02668307e-07\n",
            "  1.46807899e-03 3.35090273e-06]\n",
            " [3.36899229e-04 9.56489971e-01 2.41688768e-02 ... 3.85168799e-03\n",
            "  8.59034940e-03 2.73461228e-04]\n",
            " ...\n",
            " [2.41303540e-06 4.89103470e-07 8.26143725e-07 ... 4.07015869e-04\n",
            "  2.14992609e-02 1.18534322e-01]\n",
            " [1.51764132e-03 5.81723185e-03 6.27449638e-05 ... 3.12688046e-05\n",
            "  2.59322718e-01 9.25373266e-04]\n",
            " [7.51135933e-05 1.56294520e-05 2.72170925e-02 ... 1.89430676e-07\n",
            "  2.87980887e-03 5.69128119e-05]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# finding label based on predicted value.\n",
        "\n",
        "labeled_y = find_label(y_pred)    # calling find_label function to find corresponding label.\n",
        "print(f'The predicted label for training dataset is:')\n",
        "print(labeled_y)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KTQ37KSyb1Ja",
        "outputId": "30142d4f-808a-486c-ddc2-bd6f1b41582c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The predicted label for training dataset is:\n",
            "[[0. 0. 0. ... 1. 0. 0.]\n",
            " [0. 0. 1. ... 0. 0. 0.]\n",
            " [0. 1. 0. ... 0. 0. 0.]\n",
            " ...\n",
            " [0. 0. 0. ... 0. 0. 0.]\n",
            " [0. 0. 0. ... 0. 0. 0.]\n",
            " [0. 0. 0. ... 0. 0. 0.]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#printing the actual label of testing dataset.\n",
        "\n",
        "print('The actual label of testing dataset:')\n",
        "print(y_test)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ekKO-esSb06i",
        "outputId": "1fb8c8c2-0cfd-451e-e762-7066c1e8ef21"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The actual label of testing dataset:\n",
            "[[0 0 0 ... 1 0 0]\n",
            " [0 0 1 ... 0 0 0]\n",
            " [0 1 0 ... 0 0 0]\n",
            " ...\n",
            " [0 0 0 ... 0 0 0]\n",
            " [0 0 0 ... 0 0 0]\n",
            " [0 0 0 ... 0 0 0]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "accurate = accu(y_test, labeled_y)           # calling accuracy function to compute accuracy\n",
        "print(f'The testing accuracy is: {accurate}')      # predicted label and actual lebel.\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2sntj6ioPojn",
        "outputId": "893dedff-39e7-4b72-d22c-168ee3182cf6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The testing accuracy is: 0.8684\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "ZZmcbuLRPoVl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# The number of layers in the neural network is 3. The first and second layer i.e. hidden layers contain ReLU activation function of size 20 and 10 respectively. And the third layer i.e. output layer contains softmax function of size 10."
      ],
      "metadata": {
        "id": "iiomq9B8frKM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "n_layer = 3\n",
        "layer_sizes = [20, 10, 10]\n",
        "w_list, b_list = parameter_initialization(X_train[0], layer_sizes)\n",
        "\n",
        "f_list = [Relu, Relu, softmax]\n",
        "\n",
        "#calling the Gradient Descent algorithm to compute optimal weight vectors.\n",
        "err, list_w, list_b = Gradient_descent(X_train, y_train, n_layer, f_list, w_list, b_list, learning_rate = 0.1, nEpoch = 1000)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lhUs41CGfqBX",
        "outputId": "be9a55a5-f9ac-442d-8f17-e44ff60fa8c6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "At 0 -th iteration, training error: 2.9524093478865576, accuracy: 0.10363333333333333\n",
            "At 10 -th iteration, training error: 2.3941993875020184, accuracy: 0.25361666666666666\n",
            "At 20 -th iteration, training error: 1.9413323685925277, accuracy: 0.3891833333333333\n",
            "At 30 -th iteration, training error: 1.5938820801418603, accuracy: 0.56025\n",
            "At 40 -th iteration, training error: 1.3537449296907538, accuracy: 0.6186833333333334\n",
            "At 50 -th iteration, training error: 1.163142414642725, accuracy: 0.6617\n",
            "At 60 -th iteration, training error: 1.0148166218946282, accuracy: 0.6979833333333333\n",
            "At 70 -th iteration, training error: 0.9013894920785067, accuracy: 0.7300833333333333\n",
            "At 80 -th iteration, training error: 0.8153753310692803, accuracy: 0.75565\n",
            "At 90 -th iteration, training error: 0.7486094713286935, accuracy: 0.77565\n",
            "At 100 -th iteration, training error: 0.6962837897251575, accuracy: 0.7916\n",
            "At 110 -th iteration, training error: 0.6548455838262129, accuracy: 0.8040333333333334\n",
            "At 120 -th iteration, training error: 0.6213440648554185, accuracy: 0.8141166666666667\n",
            "At 130 -th iteration, training error: 0.5937017635304023, accuracy: 0.8229333333333333\n",
            "At 140 -th iteration, training error: 0.57040560454806, accuracy: 0.831\n",
            "At 150 -th iteration, training error: 0.5504193703654272, accuracy: 0.8374333333333334\n",
            "At 160 -th iteration, training error: 0.5331119364477599, accuracy: 0.8435666666666667\n",
            "At 170 -th iteration, training error: 0.5196027947977813, accuracy: 0.84835\n",
            "At 180 -th iteration, training error: 0.5324672329992043, accuracy: 0.8410666666666666\n",
            "At 190 -th iteration, training error: 0.6242620112961748, accuracy: 0.7975166666666667\n",
            "At 200 -th iteration, training error: 0.4887432892686249, accuracy: 0.8582666666666666\n",
            "At 210 -th iteration, training error: 0.4710941347263858, accuracy: 0.8649666666666667\n",
            "At 220 -th iteration, training error: 0.4611902925449315, accuracy: 0.8682666666666666\n",
            "At 230 -th iteration, training error: 0.45235851986044634, accuracy: 0.8712333333333333\n",
            "At 240 -th iteration, training error: 0.4442314066974211, accuracy: 0.8736166666666667\n",
            "At 250 -th iteration, training error: 0.4367033490211004, accuracy: 0.8756666666666667\n",
            "At 260 -th iteration, training error: 0.42971196287825925, accuracy: 0.8778333333333334\n",
            "At 270 -th iteration, training error: 0.42319997222781774, accuracy: 0.8796\n",
            "At 280 -th iteration, training error: 0.4171029489709355, accuracy: 0.8814833333333333\n",
            "At 290 -th iteration, training error: 0.41140836586847834, accuracy: 0.8833\n",
            "At 300 -th iteration, training error: 0.4060588556039149, accuracy: 0.8846833333333334\n",
            "At 310 -th iteration, training error: 0.40102446473116576, accuracy: 0.8865\n",
            "At 320 -th iteration, training error: 0.39627769546726704, accuracy: 0.8879833333333333\n",
            "At 330 -th iteration, training error: 0.391799164229723, accuracy: 0.8896833333333334\n",
            "At 340 -th iteration, training error: 0.3875579031077228, accuracy: 0.8908666666666667\n",
            "At 350 -th iteration, training error: 0.3835351116511867, accuracy: 0.89205\n",
            "At 360 -th iteration, training error: 0.37971011322977083, accuracy: 0.8929833333333334\n",
            "At 370 -th iteration, training error: 0.3760699298328525, accuracy: 0.894\n",
            "At 380 -th iteration, training error: 0.37260541782589945, accuracy: 0.8947833333333334\n",
            "At 390 -th iteration, training error: 0.36929964932503073, accuracy: 0.89585\n",
            "At 400 -th iteration, training error: 0.36613702733373105, accuracy: 0.8968\n",
            "At 410 -th iteration, training error: 0.36310708617234194, accuracy: 0.8974166666666666\n",
            "At 420 -th iteration, training error: 0.36019869332047655, accuracy: 0.8979666666666667\n",
            "At 430 -th iteration, training error: 0.35740789511862486, accuracy: 0.8987\n",
            "At 440 -th iteration, training error: 0.35472323248556514, accuracy: 0.8996166666666666\n",
            "At 450 -th iteration, training error: 0.3521340343887855, accuracy: 0.9005166666666666\n",
            "At 460 -th iteration, training error: 0.34963417040267325, accuracy: 0.9010666666666667\n",
            "At 470 -th iteration, training error: 0.3472203324643756, accuracy: 0.90145\n",
            "At 480 -th iteration, training error: 0.3448935101045537, accuracy: 0.9021666666666667\n",
            "At 490 -th iteration, training error: 0.3426416514084948, accuracy: 0.9027\n",
            "At 500 -th iteration, training error: 0.34046630056911714, accuracy: 0.9033\n",
            "At 510 -th iteration, training error: 0.33836476980385594, accuracy: 0.9038\n",
            "At 520 -th iteration, training error: 0.33633293548049636, accuracy: 0.9043333333333333\n",
            "At 530 -th iteration, training error: 0.33436371787786123, accuracy: 0.9049833333333334\n",
            "At 540 -th iteration, training error: 0.3324509574687004, accuracy: 0.90535\n",
            "At 550 -th iteration, training error: 0.33058512946789675, accuracy: 0.9058333333333334\n",
            "At 560 -th iteration, training error: 0.32876685820411244, accuracy: 0.9063\n",
            "At 570 -th iteration, training error: 0.3269904135763365, accuracy: 0.9067833333333334\n",
            "At 580 -th iteration, training error: 0.32524822508751683, accuracy: 0.9073333333333333\n",
            "At 590 -th iteration, training error: 0.32354688490057604, accuracy: 0.90785\n",
            "At 600 -th iteration, training error: 0.32188482576672545, accuracy: 0.9080833333333334\n",
            "At 610 -th iteration, training error: 0.3202505650341886, accuracy: 0.9084833333333333\n",
            "At 620 -th iteration, training error: 0.3186386137984966, accuracy: 0.9089\n",
            "At 630 -th iteration, training error: 0.3170536258825192, accuracy: 0.9095333333333333\n",
            "At 640 -th iteration, training error: 0.3154971160397306, accuracy: 0.9099666666666667\n",
            "At 650 -th iteration, training error: 0.3139611766250332, accuracy: 0.91045\n",
            "At 660 -th iteration, training error: 0.31244766708703803, accuracy: 0.911\n",
            "At 670 -th iteration, training error: 0.31096925371676537, accuracy: 0.9114333333333333\n",
            "At 680 -th iteration, training error: 0.3095250864723015, accuracy: 0.9118166666666667\n",
            "At 690 -th iteration, training error: 0.30810424948012005, accuracy: 0.912\n",
            "At 700 -th iteration, training error: 0.30668903939380215, accuracy: 0.9123666666666667\n",
            "At 710 -th iteration, training error: 0.30529021876508794, accuracy: 0.9128166666666667\n",
            "At 720 -th iteration, training error: 0.3039136515250747, accuracy: 0.91315\n",
            "At 730 -th iteration, training error: 0.3025598879004344, accuracy: 0.9136333333333333\n",
            "At 740 -th iteration, training error: 0.3012247934005772, accuracy: 0.9141666666666667\n",
            "At 750 -th iteration, training error: 0.2999094265640499, accuracy: 0.9145166666666666\n",
            "At 760 -th iteration, training error: 0.2986170278246729, accuracy: 0.9149833333333334\n",
            "At 770 -th iteration, training error: 0.29734430785673793, accuracy: 0.9152666666666667\n",
            "At 780 -th iteration, training error: 0.2960837046499789, accuracy: 0.9156333333333333\n",
            "At 790 -th iteration, training error: 0.2948356383945983, accuracy: 0.9160666666666667\n",
            "At 800 -th iteration, training error: 0.29360573707192833, accuracy: 0.9165\n",
            "At 810 -th iteration, training error: 0.2923871010869079, accuracy: 0.9169\n",
            "At 820 -th iteration, training error: 0.2911821184187253, accuracy: 0.9173666666666667\n",
            "At 830 -th iteration, training error: 0.28999320077909496, accuracy: 0.9175833333333333\n",
            "At 840 -th iteration, training error: 0.28882232938239183, accuracy: 0.9179\n",
            "At 850 -th iteration, training error: 0.28765951085549285, accuracy: 0.9182166666666667\n",
            "At 860 -th iteration, training error: 0.2865096725304658, accuracy: 0.9184666666666667\n",
            "At 870 -th iteration, training error: 0.2853636405002514, accuracy: 0.9188166666666666\n",
            "At 880 -th iteration, training error: 0.28423069561660225, accuracy: 0.9190666666666667\n",
            "At 890 -th iteration, training error: 0.28310933808514194, accuracy: 0.9193833333333333\n",
            "At 900 -th iteration, training error: 0.2820102163622589, accuracy: 0.9196666666666666\n",
            "At 910 -th iteration, training error: 0.2809240694873433, accuracy: 0.9200666666666667\n",
            "At 920 -th iteration, training error: 0.2798570405255415, accuracy: 0.9204\n",
            "At 930 -th iteration, training error: 0.2788044387540626, accuracy: 0.9208\n",
            "At 940 -th iteration, training error: 0.2777727462702556, accuracy: 0.9211833333333334\n",
            "At 950 -th iteration, training error: 0.276751528284503, accuracy: 0.9215333333333333\n",
            "At 960 -th iteration, training error: 0.275742953719361, accuracy: 0.9217\n",
            "At 970 -th iteration, training error: 0.274747535298215, accuracy: 0.9217833333333333\n",
            "At 980 -th iteration, training error: 0.27376768009783975, accuracy: 0.9220166666666667\n",
            "At 990 -th iteration, training error: 0.2728055628598507, accuracy: 0.9221833333333334\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "n_iteration1 = len(err)  # array of costs .\n",
        "n_iteration1 = list(i*10 for i in range(1, n_iteration1+1))\n",
        "\n",
        "plt.plot(n_iteration1, err, color = 'red', label = 'loss curve')\n",
        "plt.xlabel('iteration')\n",
        "plt.ylabel('loss')\n",
        "plt.title('loss vs iteration at gradient descent algorithm.')\n",
        "plt.legend(loc = 'upper right')\n",
        "plt.show()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 472
        },
        "id": "Z6V2jEILsb-J",
        "outputId": "a5211f4c-f220-4516-e876-4dccd1f48b2b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAjcAAAHHCAYAAABDUnkqAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjcuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/bCgiHAAAACXBIWXMAAA9hAAAPYQGoP6dpAABWH0lEQVR4nO3dd1hT9/4H8HdYCQiEDSqgCIpbLC7ErXWv1lrttXW0rjqpWq23V6sdl1avtXW2tlexVsXaOnqtda+quMWFAxXRKrhliSjk+/vj/BIIS0aSA+H9ep7zJJycnHxyCPDmO85RCCEEiIiIiMyEhdwFEBERERkSww0RERGZFYYbIiIiMisMN0RERGRWGG6IiIjIrDDcEBERkVlhuCEiIiKzwnBDREREZoXhhoiIiMwKw40ZiYiIgEKhwI0bN+QuxaQUCgVmzZoldxlFduPGDSgUCkRERMhdilnJ7/Pfrl07tGvXTraaiqM81So3uX/X7du3DwqFAvv27Svytr/++qvxCyMdhhsyO4cPH8asWbPw5MkTWetYs2YNvvnmG1lrKKmtW7eWq8Aop7LyeSuLYmJiMGvWrArxD1d5/nk3Rww3VO6lp6fjX//6l+7rw4cPY/bs2bL/sSnol121atWQnp6Od955x/RFFdHWrVsxe/ZsucsotR07dmDHjh1GfY2y8nkri2JiYjB79myzCzdt2rRBeno62rRpo1vHcFO2MNxQuadSqWBlZWX013n69KlB9qNQKKBSqWBpaWmQ/ZV3aWlpRtu3jY0NbGxsjLZ/qliePXsGjUYDCwsLqFQqWFjwT2hZxe9MBbBkyRLUq1cPSqUSVapUwdixY/P8lxkbG4t+/frBy8sLKpUK3t7eGDhwIJKSknTb7Ny5E61atYKTkxPs7e0RGBiIf/7zn4W+dv369dG+ffs86zUaDapWrYo33nhDty4yMhLBwcFwcHCAo6MjGjRogG+//fal7y/nmJtZs2bhww8/BAD4+flBoVDk6Zv/+eefERwcDFtbW7i4uGDgwIG4deuW3j7btWuH+vXr4+TJk2jTpg3s7Ox073Xz5s3o0aMHqlSpAqVSCX9/f3z22WfIysrSe/4ff/yB+Ph4XQ3Vq1cHUPCYmz179qB169aoVKkSnJyc0KdPH1y8eFFvm1mzZkGhUODq1asYOnQonJycoFarMWzYsCKFr7/++gv9+/eHr68vlEolfHx88MEHHyA9PV23zdChQ7F48WLdsdUuhdFoNJg1axaqVKkCOzs7tG/fHjExMahevTqGDh2q2047VmL//v0YM2YMPDw84O3tDQCIj4/HmDFjEBgYCFtbW7i6uqJ///75/td/4cIFdOjQAba2tvD29sbnn38OjUaTZ7v8xrFkZGTgk08+QUBAgO4YTJ06FRkZGXrbKRQKjBs3Dps2bUL9+vWhVCpRr149bNu2TbdNUT5v+Vm2bBn8/f1ha2uLZs2a4a+//sp3u6LWWpSfzWfPnmHWrFmoVasWVCoVKleujNdffx3Xrl3TbaPRaPDNN9+gXr16UKlU8PT0xKhRo/D48WO9fVWvXh09e/bEwYMH0axZM6hUKtSoUQM//fSTbpuIiAj0798fANC+fXvdsSlsnMrZs2cxdOhQ1KhRAyqVCl5eXnj33Xfx8OHDQo+ntvaifAYB4Pr16+jfvz9cXFxgZ2eHFi1a4I8//tDbRjtWJjIyEv/6179QtWpV2NnZITk5Oc+Ym8J+3nPW98UXX8Db2xsqlQodO3bE1atX9bbR/t45e/Ys2rZtCzs7OwQEBOjG6+zfvx/NmzeHra0tAgMDsWvXrpcel4rK+P/ukqxmzZqF2bNno1OnTnj//fdx+fJlLF26FMePH8ehQ4dgbW2N58+fo0uXLsjIyMD48ePh5eWF27dvY8uWLXjy5AnUajUuXLiAnj17omHDhvj000+hVCpx9epVHDp0qNDXHzBgAGbNmoXExER4eXnp1h88eBB37tzBwIEDAUi/nN966y107NgRX331FQDg4sWLOHToECZOnFjk9/v666/jypUrWLt2LebPnw83NzcAgLu7OwDgiy++wIwZM/Dmm29i+PDhuH//PhYuXIg2bdrg9OnTcHJy0u3r4cOH6NatGwYOHIi3334bnp6eAKRf2vb29pg0aRLs7e2xZ88ezJw5E8nJyZg7dy4A4OOPP0ZSUhL+/vtvzJ8/HwBgb29fYN27du1Ct27dUKNGDcyaNQvp6elYuHAhQkNDcerUqTy/KN988034+fkhPDwcp06dwo8//ggPDw/dsSvI+vXr8fTpU7z//vtwdXXFsWPHsHDhQvz9999Yv349AGDUqFG4c+cOdu7ciVWrVhXpuE+fPh1z5sxBr1690KVLF5w5cwZdunTBs2fP8t1+zJgxcHd3x8yZM3UtN8ePH8fhw4cxcOBAeHt748aNG1i6dCnatWuHmJgY2NnZAQASExPRvn17ZGZm4qOPPkKlSpWwbNky2NravrROjUaD3r174+DBgxg5ciTq1KmDc+fOYf78+bhy5Qo2bdqkt/3BgwexYcMGjBkzBg4ODliwYAH69euHmzdvwtXV9aWft/z897//xahRo9CyZUuEhYXh+vXr6N27N1xcXODj41PsWovys5mVlYWePXti9+7dGDhwICZOnIiUlBTs3LkT58+fh7+/PwDpex8REYFhw4ZhwoQJiIuLw6JFi3D69Gnd7wutq1ev4o033sB7772HIUOGYPny5Rg6dCiCg4NRr149tGnTBhMmTMCCBQvwz3/+E3Xq1AEA3W1+du7cievXr2PYsGHw8vLChQsXsGzZMly4cAFHjhwpNGQX9TN49+5dtGzZEk+fPsWECRPg6uqKlStXonfv3vj111/x2muv6W3/2WefwcbGBlOmTEFGRka+LYFF+Xn/8ssvYWFhgSlTpiApKQlz5szBoEGDcPToUb3tHj9+jJ49e2LgwIHo378/li5dioEDB2L16tUICwvD6NGj8Y9//ANz587FG2+8gVu3bsHBwaHA41JhCTIbK1asEABEXFycEEKIe/fuCRsbG9G5c2eRlZWl227RokUCgFi+fLkQQojTp08LAGL9+vUF7nv+/PkCgLh//36xarp8+bIAIBYuXKi3fsyYMcLe3l48ffpUCCHExIkThaOjo8jMzCzW/oUQAoD45JNPdF/PnTtX7zho3bhxQ1haWoovvvhCb/25c+eElZWV3vq2bdsKAOK7777L83ramnMaNWqUsLOzE8+ePdOt69Gjh6hWrVqebePi4gQAsWLFCt26oKAg4eHhIR4+fKhbd+bMGWFhYSEGDx6sW/fJJ58IAOLdd9/V2+drr70mXF1d87xWUWoPDw8XCoVCxMfH69aNHTtWFPXXQ2JiorCyshJ9+/bVWz9r1iwBQAwZMkS3TvsZbdWqVZ7vdX61RUVFCQDip59+0q0LCwsTAMTRo0d16+7duyfUanWe73vbtm1F27ZtdV+vWrVKWFhYiL/++kvvdb777jsBQBw6dEi3DoCwsbERV69e1a07c+ZMns9zQZ+3/Dx//lx4eHiIoKAgkZGRoVu/bNkyAaBEtRblZ3P58uUCgPj666/zPKbRaIQQQvz1118CgFi9erXe49u2bcuzvlq1agKAOHDggG7dvXv3hFKpFJMnT9atW79+vQAg9u7dW8hRyZbfZ2Dt2rV5Xiv377rifAa1n5+cxzUlJUX4+fmJ6tWr635X7t27VwAQNWrUyFOX9rGc76ugn3fttnXq1NH7nn/77bcCgDh37pxunfb3zpo1a3TrLl26JAAICwsLceTIEd367du35/k9QtnYLWXGdu3ahefPnyMsLEyvb3jEiBFwdHTUNcOq1WoAwPbt2wvs2tC2aGzevDnf5v+C1KpVC0FBQVi3bp1uXVZWFn799Vf06tVL99+2k5MT0tLSsHPnzmK9x+LYsGEDNBoN3nzzTTx48EC3eHl5oWbNmti7d6/e9kqlEsOGDcuzn5wtBCkpKXjw4AFat26Np0+f4tKlS8WuKyEhAdHR0Rg6dChcXFx06xs2bIhXX30VW7duzfOc0aNH633dunVrPHz4EMnJyYW+Vs7a09LS8ODBA7Rs2RJCCJw+fbrYtQPA7t27kZmZiTFjxuitHz9+fIHPGTFiRJ4xRzlre/HiBR4+fIiAgAA4OTnh1KlTuse2bt2KFi1aoFmzZrp17u7uGDRo0EtrXb9+PerUqYPatWvrfQY6dOgAAHk+A506ddK1agDS98TR0RHXr19/6Wvl58SJE7h37x5Gjx6t1wIwdOhQ3c9hcWstys/mb7/9Bjc3t3y/J9rWkPXr10OtVuPVV1/Ve73g4GDY29vnOTZ169ZF69atdV+7u7sjMDCwxMcG0P8MPHv2DA8ePECLFi0AQO8zkFtxPoNbt25Fs2bN0KpVK906e3t7jBw5Ejdu3EBMTIze9kOGDClSq+DLDBs2TO97rj12uY+Xvb29rkUbAAIDA+Hk5IQ6deqgefPmuvXa+6U53uaM4caMxcfHA5B+OHKysbFBjRo1dI/7+flh0qRJ+PHHH+Hm5oYuXbpg8eLFeuNtBgwYgNDQUAwfPhyenp4YOHAgfvnllyIFnQEDBuDQoUO4ffs2AKkv+969exgwYIBumzFjxqBWrVro1q0bvL298e677+qNbTCE2NhYCCFQs2ZNuLu76y0XL17EvXv39LavWrVqvk3QFy5cwGuvvQa1Wg1HR0e4u7vj7bffBgC9Y1ZUBX2fAKkJ/8GDB3kG3fr6+up97ezsDAB5xkbkdvPmTV2Isre3h7u7O9q2bVvi2nPWHxAQoLfexcVFV1dufn5+edalp6dj5syZ8PHxgVKphJubG9zd3fHkyRO92uLj41GzZs08z8/v+OUWGxuLCxcu5Pn+16pVCwDyfAZyH2dAOtYvO84F0R6r3PVbW1ujRo0aJaq1KD+b165dQ2BgYKED72NjY5GUlAQPD488r5mammr0YwMAjx49wsSJE+Hp6QlbW1u4u7vrPiuFfT6L8xmMj48v8Gct57608vuslkRRf2a9vb3zdL+p1Wq9LkvtuvyeTxKOuSEAwLx58zB06FBs3rwZO3bswIQJExAeHo4jR47A29sbtra2OHDgAPbu3Ys//vgD27Ztw7p169ChQwfs2LGj0Jk/AwYMwPTp07F+/XqEhYXhl19+gVqtRteuXXXbeHh4IDo6Gtu3b8eff/6JP//8EytWrMDgwYOxcuVKg7xHjUYDhUKBP//8M996c/eR5/ff2pMnT9C2bVs4Ojri008/hb+/P1QqFU6dOoVp06YVq1WrNAo63kKIAp+TlZWFV199FY8ePcK0adNQu3ZtVKpUCbdv38bQoUNNVjuQ/7EdP348VqxYgbCwMISEhECtVkOhUGDgwIEGq02j0aBBgwb4+uuv83089x+QkhxnQylqraX52cz9eh4eHli9enW+j+ceR2SMY/Pmm2/i8OHD+PDDDxEUFAR7e3toNBp07drVpJ/PnAzRagMU/XgVtJ2cn8XyiOHGjFWrVg0AcPnyZb3/Cp8/f464uDh06tRJb/sGDRqgQYMG+Ne//oXDhw8jNDQU3333HT7//HMAgIWFBTp27IiOHTvi66+/xr///W98/PHH2Lt3b5595eTn54dmzZph3bp1GDduHDZs2IC+fftCqVTqbWdjY4NevXqhV69e0Gg0GDNmDL7//nvMmDEjz39khSlo0KG/vz+EEPDz89P991tc+/btw8OHD7Fhwwa9c1zExcUVuY7ccn6fcrt06RLc3NxQqVKlEtWb07lz53DlyhWsXLkSgwcP1q3PryuwqLUD2fVfvXpV77/chw8fFuu/yl9//RVDhgzBvHnzdOuePXuWZ2ZftWrVEBsbm+f5+R2/3Pz9/XHmzBl07NixWO+xMCU5VrGxsbruJUDqhouLi0OjRo1KVOvLfjb9/f1x9OhRvHjxQm9QcE7+/v7YtWsXQkNDDfYHvTjH5vHjx9i9ezdmz56NmTNn6tbn973OrTifwWrVqhX4s5ZzX8VlqM8TGQa7pcxYp06dYGNjgwULFuil+//+979ISkpCjx49AADJycnIzMzUe26DBg1gYWGhm3L66NGjPPsPCgoCgDzTUvMzYMAAHDlyBMuXL8eDBw/0uqQA5JnqaWFhgYYNGxZ5/zlpg0DuP4qvv/46LC0tMXv27Dz/7QghijTdVPvfU87nP3/+HEuWLMm3jqJ09VSuXBlBQUFYuXKlXs3nz5/Hjh070L1795fuoyjyq10Ike90+4KOYX46duwIKysrLF26VG/9okWLil1f7u/LwoUL9abYA0D37t1x5MgRHDt2TLfu/v37BbY45PTmm2/i9u3b+OGHH/I8lp6eXqJz7hTnWDVp0gTu7u747rvv8Pz5c936iIiIPM8vaq1F+dns168fHjx4kO/3RHvM33zzTWRlZeGzzz7Ls01mZmaJTlJYnGOT3+cTQJFOjFecz2D37t1x7NgxREVF6dalpaVh2bJlqF69OurWrfvS18tPUX/ejUk77u/Bgwey1lEWsOXGjLm7u2P69OmYPXs2unbtit69e+Py5ctYsmQJmjZtqhsnsmfPHowbNw79+/dHrVq1kJmZiVWrVsHS0hL9+vUDAHz66ac4cOAAevTogWrVquHevXtYsmQJvL299QbmFeTNN9/ElClTMGXKFLi4uORp6Rk+fDgePXqEDh06wNvbG/Hx8Vi4cCGCgoIKnTqan+DgYADS9MyBAwfC2toavXr1gr+/Pz7//HNMnz4dN27cQN++feHg4IC4uDhs3LgRI0eOxJQpUwrdd8uWLeHs7IwhQ4ZgwoQJUCgUWLVqVb5Nw8HBwVi3bh0mTZqEpk2bwt7eHr169cp3v3PnzkW3bt0QEhKC9957TzcVXK1WG+wyCLVr14a/vz+mTJmC27dvw9HREb/99lu+rSvaYzhhwgR06dIFlpaWeoMcc/L09MTEiRMxb9489O7dG127dsWZM2fw559/ws3Nrcj/0fbs2ROrVq2CWq1G3bp1ERUVhV27dsHV1VVvu6lTp2LVqlXo2rUrJk6cqJsKXq1aNZw9e7bQ13jnnXfwyy+/YPTo0di7dy9CQ0ORlZWFS5cu4ZdffsH27dvRpEmTItWrVdDnLb/WNmtra3z++ecYNWoUOnTogAEDBiAuLg4rVqzIM+amqLUW5Wdz8ODB+OmnnzBp0iQcO3YMrVu3RlpaGnbt2oUxY8agT58+aNu2LUaNGoXw8HBER0ejc+fOsLa2RmxsLNavX49vv/1W77xURREUFARLS0t89dVXSEpKglKpRIcOHeDh4ZFnW0dHR7Rp0wZz5szBixcvULVqVezYsSPfVtHcivMZ/Oijj7B27Vp069YNEyZMgIuLC1auXIm4uDj89ttvJT4xX3F+3o3l2LFjaN++PT755BNePsXU07PIeHJPj9RatGiRqF27trC2thaenp7i/fffF48fP9Y9fv36dfHuu+8Kf39/oVKphIuLi2jfvr3YtWuXbpvdu3eLPn36iCpVqggbGxtRpUoV8dZbb4krV64Uub7Q0FABQAwfPjzPY7/++qvo3Lmz8PDwEDY2NsLX11eMGjVKJCQkvHS/yDUVXAghPvvsM1G1alVhYWGR55j89ttvolWrVqJSpUqiUqVKonbt2mLs2LHi8uXLum3atm0r6tWrl+/rHTp0SLRo0ULY2tqKKlWqiKlTp+qmZeacGpqamir+8Y9/CCcnJwFAN000v6ngQgixa9cuERoaKmxtbYWjo6Po1auXiImJ0dtGOxU897Tfgr73ucXExIhOnToJe3t74ebmJkaMGKGb3pyznszMTDF+/Hjh7u4uFArFS6eFZ2ZmihkzZggvLy9ha2srOnToIC5evChcXV3F6NGj89R5/PjxPPt4/PixGDZsmHBzcxP29vaiS5cu4tKlS6JatWp6U3mFEOLs2bOibdu2QqVSiapVq4rPPvtM/Pe//33pVHAhpOnYX331lahXr55QKpXC2dlZBAcHi9mzZ4ukpCTddgDE2LFj89SZXz2Ffd7ys2TJEuHn5yeUSqVo0qSJOHDgQIlrLerP5tOnT8XHH38s/Pz8hLW1tfDy8hJvvPGGuHbtmt52y5YtE8HBwcLW1lY4ODiIBg0aiKlTp4o7d+7oHYMePXrkeV/5vYcffvhB1KhRQ1haWr50Wvjff/8tXnvtNeHk5CTUarXo37+/uHPnTp6f8fw+70X9DAohxLVr18Qbb7whnJychEqlEs2aNRNbtmzR20Y7hTu/U2TkNxW8oJ/3gvaT3++Bgn7vFHS8c39Gta+V+/dhRaQQgqORiMjwnjx5AmdnZ3z++ef4+OOP5S6HKiB+BisujrkholLLefkGLe1YidyXPyAyBn4GKSeOuSGiUlu3bh0iIiLQvXt32Nvb4+DBg1i7di06d+6M0NBQucujCoCfQcqJ4YaISq1hw4awsrLCnDlzkJycrBvgqT2NAJGx8TNIOXHMDREREZkVjrkhIiIis8JwQ0RERGalwo250Wg0uHPnDhwcHHi6bCIionJCCIGUlBRUqVLlpSdbrHDh5s6dO3kujkdERETlw61bt+Dt7V3oNhUu3Dg4OACQDo6jo6PM1RAREVFRJCcnw8fHR/d3vDAVLtxou6IcHR0ZboiIiMqZogwp4YBiIiIiMisMN0RERGRWGG6IiIjIrFS4MTdERGQesrKy8OLFC7nLIAOysbF56TTvopA13CxduhRLly7FjRs3AAD16tXDzJkz0a1btwKfs379esyYMQM3btxAzZo18dVXX6F79+4mqpiIiOQmhEBiYiKePHkidylkYBYWFvDz84ONjU2p9iNruPH29saXX36JmjVrQgiBlStXok+fPjh9+jTq1auXZ/vDhw/jrbfeQnh4OHr27Ik1a9agb9++OHXqFOrXry/DOyAiIlPTBhsPDw/Y2dnxhKxmQnuS3YSEBPj6+pbq+1rmLpzp4uKCuXPn4r333svz2IABA5CWloYtW7bo1rVo0QJBQUH47rvvirT/5ORkqNVqJCUlcSo4EVE5k5WVhStXrsDDwwOurq5yl0MGlpSUhDt37iAgIADW1tZ6jxXn73eZGVCclZWFyMhIpKWlISQkJN9toqKi0KlTJ711Xbp0QVRUVIH7zcjIQHJyst5CRETlk3aMjZ2dncyVkDFou6OysrJKtR/Zw825c+dgb28PpVKJ0aNHY+PGjahbt26+2yYmJsLT01NvnaenJxITEwvcf3h4ONRqtW7hpReIiMo/dkWZJ0N9X2UPN4GBgYiOjsbRo0fx/vvvY8iQIYiJiTHY/qdPn46kpCTdcuvWLYPtm4iIiMoe2aeC29jYICAgAAAQHByM48eP49tvv8X333+fZ1svLy/cvXtXb93du3fh5eVV4P6VSiWUSqVhiyYiIiqmdu3aISgoCN98843cpZg92VtuctNoNMjIyMj3sZCQEOzevVtv3c6dOwsco0NEREQVj6wtN9OnT0e3bt3g6+uLlJQUrFmzBvv27cP27dsBAIMHD0bVqlURHh4OAJg4cSLatm2LefPmoUePHoiMjMSJEyewbNkyOd+G5MUL4P59ICMD8POTuxoiIiKjycrKgkKhMMgJ94xB1qru3buHwYMHIzAwEB07dsTx48exfft2vPrqqwCAmzdvIiEhQbd9y5YtsWbNGixbtgyNGjXCr7/+ik2bNpWNc9wcPAhUrQrwhIJERFQEjx8/xuDBg+Hs7Aw7Ozt069YNsbGxusfj4+PRq1cvODs7o1KlSqhXrx62bt2qe+6gQYPg7u4OW1tb1KxZEytWrCjwtTQaDebMmYOAgAAolUr4+vriiy++AADs27cPCoVC76SI0dHRUCgUupPsRkREwMnJCb///jvq1q0LpVKJH3/8ESqVKs/JFCdOnIgOHTrovj548CBat24NW1tb+Pj4YMKECUhLSyvl0SucrC03//3vfwt9fN++fXnW9e/fH/379zdSRaXg7CzdPn4sbx1ERBWNEMDTp/K8tp0dUMIZPkOHDkVsbCx+//13ODo6Ytq0aejevTtiYmJgbW2NsWPH4vnz5zhw4AAqVaqEmJgY2NvbAwBmzJiBmJgY/Pnnn3Bzc8PVq1eRnp5e4GtNnz4dP/zwA+bPn49WrVohISEBly5dKla9T58+xVdffYUff/wRrq6u8Pb2xsyZM/Hbb7/pzk2XlZWFdevW6YLTtWvX0LVrV3z++edYvnw57t+/j3HjxmHcuHGFhrHSkn1AsdnIGW6EKPGHnYiIiunpU+D//+ibXGoqUKlSsZ+mDTWHDh1Cy5YtAQCrV6+Gj48PNm3ahP79++PmzZvo168fGjRoAACoUaOG7vk3b95E48aN0aRJEwBA9erVC3ytlJQUfPvtt1i0aBGGDBkCAPD390erVq2KVfOLFy+wZMkSNGrUSLdu4MCBWLNmjS7c7N69G0+ePEG/fv0ASKdjGTRoEMLCwgAANWvWxIIFC9C2bVssXboUKpWqWDUUVdnsLCuPnJyk2+fPgWfPZC2FiIjKtosXL8LKygrNmzfXrXN1dUVgYCAuXrwIAJgwYQI+//xzhIaG4pNPPsHZs2d1277//vuIjIxEUFAQpk6disOHDxf6WhkZGejYsWOparaxsUHDhg311g0aNAj79u3DnTt3AEgBrUePHnD6/7+JZ86cQUREBOzt7XVLly5doNFoEBcXV6p6CsNwYygODoB2YBW7poiITMfOTmpBkWMx4pmShw8fjuvXr+Odd97BuXPn0KRJEyxcuBAA0K1bN8THx+ODDz7AnTt30LFjR0yZMiXf/dja2hb6OtpBwTmvxpTf1dZtbW3znGSvadOm8Pf3R2RkJNLT07Fx40YMGjRI93hqaipGjRqF6Oho3XLmzBnExsbC39+/aAeiBBhuDMXCIrv1hleqJSIyHYVC6hqSYynhEIQ6deogMzMTR48e1a17+PAhLl++rHeWfh8fH4wePRobNmzA5MmT8cMPP+gec3d3x5AhQ/Dzzz/jm2++KXDmcM2aNWFra5vnVCo59wNAbwJPdHR0kd/LoEGDsHr1avzvf/+DhYUFevTooXvslVdeQUxMDAICAvIspb3yd2EYbgxJG27YckNERIWoWbMm+vTpgxEjRuDgwYM4c+YM3n77bVStWhV9+vQBAISFhWH79u2Ii4vDqVOnsHfvXtSpUwcAMHPmTGzevBlXr17FhQsXsGXLFt1jualUKkybNg1Tp07FTz/9hGvXruHIkSO6ST0BAQHw8fHBrFmzEBsbiz/++APz5s0r8nsZNGgQTp06hS+++AJvvPGG3olzp02bhsOHD2PcuHGIjo5GbGwsNm/ejHHjxpX00BUJw40hccYUEREV0YoVKxAcHIyePXsiJCQEQghs3bpVdzXsrKwsjB07FnXq1EHXrl1Rq1YtLFmyBIA0/mX69Olo2LAh2rRpA0tLS0RGRhb4WjNmzMDkyZMxc+ZM1KlTBwMGDMC9e/cAANbW1li7di0uXbqEhg0b4quvvsLnn39e5PcREBCAZs2a4ezZs3pdUgDQsGFD7N+/H1euXEHr1q3RuHFjzJw5E1WqVCnu4SoWhcjZyVYBFOeS6cX26qvArl3AqlXA228bdt9ERIRnz54hLi4Ofn5+RptpQ/Ip7PtbnL/fbLkxJHZLERERyY7hxpDYLUVERCQ7hhtD0oYbzpYiIiKSDcONIbFbioiISHYMN4bEbikiIpOoYHNhKgxDfV8ZbgyJ3VJEREalnSb9VK4LZZJRPX/+HABgaWlZqv3wwpmGxG4pIiKjsrS0hJOTk+4cLXZ2dnkuCUDlk0ajwf3792FnZwcrq9LFE4YbQ2K3FBGR0Xl5eQGALuCQ+bCwsICvr2+pAyvDjSGxW4qIyOgUCgUqV64MDw+PfC/wSOWXjY2N7kKepcFwY0jabqmUFCAzEyhlsxoRERXM0tKy1GMzyDxxQLEhacMNwNYbIiIimTDcGJK1NWBvL91nuCEiIpIFw42hccYUERGRrBhuDI0zpoiIiGTFcGNonDFFREQkK4YbQ2O3FBERkawYbgyN3VJERESyYrgxNHZLERERyYrhxtDYLUVERCQrhhtDY7cUERGRrBhuDI3dUkRERLJiuDE0dksRERHJiuHG0NgtRUREJCuGG0NjtxQREZGsGG4MTdst9eQJIISclRAREVVIDDeGpm25ycoCUlLkrYWIiKgCYrgxNFtbwMZGus+uKSIiIpNjuDE0hYIzpoiIiGTEcGMMnDFFREQkG4YbY+CMKSIiItkw3BgDu6WIiIhkw3BjDGy5ISIikg3DjTFwzA0REZFsGG6Mgd1SREREsmG4MQZ2SxEREcmG4cYY2C1FREQkG4YbY2C3FBERkWwYboyB3VJERESyYbgxBnZLERERyYbhxhjYLUVERCQbhhtj0LbcPHsmLURERGQyDDfG4OgoXR0c4LgbIiIiE2O4MQYLC0Ctlu6za4qIiMikGG6MhTOmiIiIZCFruAkPD0fTpk3h4OAADw8P9O3bF5cvXy70OREREVAoFHqLSqUyUcXFwBlTREREspA13Ozfvx9jx47FkSNHsHPnTrx48QKdO3dGWlpaoc9zdHREQkKCbomPjzdRxcXAGVNERESysJLzxbdt26b3dUREBDw8PHDy5Em0adOmwOcpFAp4eXkZu7zSYbcUERGRLMrUmJukpCQAgIuLS6Hbpaamolq1avDx8UGfPn1w4cIFU5RXPOyWIiIikkWZCTcajQZhYWEIDQ1F/fr1C9wuMDAQy5cvx+bNm/Hzzz9Do9GgZcuW+Pvvv/PdPiMjA8nJyXqLSbBbioiISBaydkvlNHbsWJw/fx4HDx4sdLuQkBCEhITovm7ZsiXq1KmD77//Hp999lme7cPDwzF79myD1/tS7JYiIiKSRZlouRk3bhy2bNmCvXv3wtvbu1jPtba2RuPGjXH16tV8H58+fTqSkpJ0y61btwxR8suxW4qIiEgWsrbcCCEwfvx4bNy4Efv27YOfn1+x95GVlYVz586he/fu+T6uVCqhVCpLW2rxsVuKiIhIFrKGm7Fjx2LNmjXYvHkzHBwckJiYCABQq9WwtbUFAAwePBhVq1ZFeHg4AODTTz9FixYtEBAQgCdPnmDu3LmIj4/H8OHDZXsf+WK3FBERkSxkDTdLly4FALRr105v/YoVKzB06FAAwM2bN2Fhkd179vjxY4wYMQKJiYlwdnZGcHAwDh8+jLp165qq7KJhtxQREZEsFEIIIXcRppScnAy1Wo2kpCQ4Ojoa74UuXwZq15Yuovn/U9yJiIioZIrz97tMDCg2S9qWm+RkICtL3lqIiIgqEIYbY9EOKAbYckNERGRCDDfGYmMD2NlJ9znuhoiIyGQYboyJM6aIiIhMjuHGmDhjioiIyOQYboyJJ/IjIiIyOYYbY2LLDRERkckx3BiTq6t0++iRvHUQERFVIAw3xuTmJt3evy9vHURERBUIw40xubtLtw8eyFsHERFRBcJwY0xsuSEiIjI5hhtjYssNERGRyTHcGBNbboiIiEyO4caY2HJDRERkcgw3xqRtuUlNBZ49k7cWIiKiCoLhxpjUasDKSrrP1hsiIiKTYLgxJoWC426IiIhMjOHG2LTjbhhuiIiITILhxti0LTfsliIiIjIJhhtjY8sNERGRSTHcGBungxMREZkUw42xcUAxERGRSTHcGBtbboiIiEyK4cbY2HJDRERkUgw3xsaWGyIiIpNiuDE2ttwQERGZFMONsWlbbh4+BDQaeWshIiKqABhujM3VVbrVaIDHj+WthYiIqAJguDE2GxvpApoAx90QERGZAMONKXDcDRERkckw3JgCZ0wRERGZDMONKbDlhoiIyGQYbkyBLTdEREQmw3BjCmy5ISIiMhmGG1Ngyw0REZHJMNyYAltuiIiITIbhxhTYckNERGQyDDemwJYbIiIik2G4MQVtyw3DDRERkdEx3JiCNtw8fSotREREZDQMN6bg4ABYW0v3Oe6GiIjIqBhuTEGh4KBiIiIiE2G4MRUOKiYiIjIJhhtTYcsNERGRSTDcmApbboiIiEyC4cZU2HJDRERkEgw3psKWGyIiIpNguDEVttwQERGZBMONqbDlhoiIyCQYbkyFLTdEREQmwXBjKmy5ISIiMgmGG1PRttw8egRkZclbCxERkRmTNdyEh4ejadOmcHBwgIeHB/r27YvLly+/9Hnr169H7dq1oVKp0KBBA2zdutUE1ZaSq6t0q9EAjx/LWwsREZEZkzXc7N+/H2PHjsWRI0ewc+dOvHjxAp07d0ZaWlqBzzl8+DDeeustvPfeezh9+jT69u2Lvn374vz58yasvASsrQEnJ+k+x90QEREZjUIIIeQuQuv+/fvw8PDA/v370aZNm3y3GTBgANLS0rBlyxbduhYtWiAoKAjffffdS18jOTkZarUaSUlJcHR0NFjtRVKzJnD1KnDgANC6tWlfm4iIqBwrzt/vMjXmJikpCQDg4uJS4DZRUVHo1KmT3rouXbogKioq3+0zMjKQnJyst8iGM6aIiIiMrsyEG41Gg7CwMISGhqJ+/foFbpeYmAhPT0+9dZ6enkhMTMx3+/DwcKjVat3i4+Nj0LqLhTOmiIiIjK7MhJuxY8fi/PnziIyMNOh+p0+fjqSkJN1y69Ytg+6/WNhyQ0REZHRWchcAAOPGjcOWLVtw4MABeHt7F7qtl5cX7t69q7fu7t278PLyynd7pVIJpVJpsFpLRRtu2HJDRERkNLK23AghMG7cOGzcuBF79uyBn5/fS58TEhKC3bt3663buXMnQkJCjFWm4bBbioiIyOhkbbkZO3Ys1qxZg82bN8PBwUE3bkatVsPW1hYAMHjwYFStWhXh4eEAgIkTJ6Jt27aYN28eevTogcjISJw4cQLLli2T7X0UGbuliIiIjE7WlpulS5ciKSkJ7dq1Q+XKlXXLunXrdNvcvHkTCQkJuq9btmyJNWvWYNmyZWjUqBF+/fVXbNq0qdBByGUGW26IiIiMrkyd58YUZD3PzbFjQPPmgK8vEB9v2tcmIiIqx8rteW7MXs6Wm4qVKYmIiEyG4caUKleWbtPTgf8/YSEREREZFsONKdnaAs7O0v3bt+WthYiIyEwx3JhalSrS7Z078tZBRERkphhuTK1qVemWLTdERERGwXBjagw3RERERsVwY2oMN0REREbFcGNq2nDDMTdERERGwXBjatoBxWy5ISIiMgqGG1NjtxQREZFRMdyYmjbc3L0LZGbKWwsREZEZYrgxNQ8PwNIS0GikgENEREQGxXBjahYW2ZdhYNcUERGRwTHcyIHjboiIiIyG4UYODDdERERGw3AjB57rhoiIyGgYbuTAc90QEREZDcONHNgtRUREZDQMN3JguCEiIjIahhs5MNwQEREZDcONHLRjblJSpIWIiIgMhuFGDg4O0gJwxhQREZGBMdzIhV1TRERERsFwIxeGGyIiIqNguJGLdtwNu6WIiIgMiuFGLmy5ISIiMgqGG7kw3BARERkFw41cGG6IiIiMguFGLrx4JhERkVEw3MhFO6A4IQHQaOSthYiIyIww3MjFywuwsAAyM4F79+SuhoiIyGww3MjFygrw9JTuc9wNERGRwZQo3KxcuRJ//PGH7uupU6fCyckJLVu2RHx8vMGKM3scd0NERGRwJQo3//73v2FrawsAiIqKwuLFizFnzhy4ubnhgw8+MGiBZk077oYtN0RERAZjVZIn3bp1CwEBAQCATZs2oV+/fhg5ciRCQ0PRrl07Q9Zn3jgdnIiIyOBK1HJjb2+Phw8fAgB27NiBV199FQCgUqmQnp5uuOrMHcMNERGRwZWo5ebVV1/F8OHD0bhxY1y5cgXdu3cHAFy4cAHVq1c3ZH3mjeGGiIjI4ErUcrN48WKEhITg/v37+O233+Dq6goAOHnyJN566y2DFmjWePFMIiIig1MIIYTcRZhScnIy1Go1kpKS4OjoKG8xFy4A9esDzs7Ao0fy1kJERFSGFefvd4labrZt24aDBw/qvl68eDGCgoLwj3/8A48fPy7JLismbbfU48cAxyoREREZRInCzYcffojk5GQAwLlz5zB58mR0794dcXFxmDRpkkELNGtqNWBnJ93nuBsiIiKDKNGA4ri4ONStWxcA8Ntvv6Fnz57497//jVOnTukGF1MRKBTSuJurV6VxN/8/vZ6IiIhKrkQtNzY2Nnj69CkAYNeuXejcuTMAwMXFRdeiQ0XEGVNEREQGVaKWm1atWmHSpEkIDQ3FsWPHsG7dOgDAlStX4O3tbdACzR7DDRERkUGVqOVm0aJFsLKywq+//oqlS5ei6v//gf7zzz/RtWtXgxZo9nx8pFtek4uIiMggStRy4+vriy1btuRZP3/+/FIXVOHUqiXdXr4sbx1ERERmokThBgCysrKwadMmXLx4EQBQr1499O7dG5aWlgYrrkLQhpsrV+Stg4iIyEyUKNxcvXoV3bt3x+3btxEYGAgACA8Ph4+PD/744w/4+/sbtEiz9v/HDzdvSue6+f+rrRMREVHJlGjMzYQJE+Dv749bt27h1KlTOHXqFG7evAk/Pz9MmDDB0DWaNzc36QzFQgCxsXJXQ0REVO6VKNzs378fc+bMgYuLi26dq6srvvzyS+zfv99gxVUICkV26w3H3RAREZVaicKNUqlESkpKnvWpqamwsbEpdVEVDsfdEBERGUyJwk3Pnj0xcuRIHD16FEIICCFw5MgRjB49Gr179zZ0jeaPLTdEREQGU6Jws2DBAvj7+yMkJAQqlQoqlQotW7ZEQEAAvvnmmyLv58CBA+jVqxeqVKkChUKBTZs2Fbr9vn37oFAo8iyJiYkleRtlB8MNERGRwZRotpSTkxM2b96Mq1ev6qaC16lTBwHFvDZSWloaGjVqhHfffRevv/56kZ93+fJlvcude3h4FOt1y5yc4UYIaRwOERERlUiRw83Lrva9d+9e3f2vv/66SPvs1q0bunXrVtQSdDw8PODk5FTs55VZ/v5SoElKAu7fB8p7WCMiIpJRkcPN6dOni7SdwgStDkFBQcjIyED9+vUxa9YshIaGFrhtRkYGMjIydF+XyQt72toC1aoBN25IrTcMN0RERCVW5HCTs2VGLpUrV8Z3332HJk2aICMjAz/++CPatWuHo0eP4pVXXsn3OeHh4Zg9e7aJKy2BwMDscNO6tdzVEBERlVslvvyCHAIDA3VnRAaAli1b4tq1a5g/fz5WrVqV73OmT5+u16WWnJwMH+3FKsuSWrWA7ds5qJiIiKiUylW4yU+zZs1w8ODBAh9XKpVQKpUmrKiEtKGN57ohIiIqlRJNBS9LoqOjUblyZbnLKD1OByciIjIIWVtuUlNTcfXqVd3XcXFxiI6OhouLC3x9fTF9+nTcvn0bP/30EwDgm2++gZ+fH+rVq4dnz57hxx9/xJ49e7Bjxw653oLhaMPNtWvAixeAtbW89RAREZVTsoabEydOoH379rqvtWNjhgwZgoiICCQkJODmzZu6x58/f47Jkyfj9u3bsLOzQ8OGDbFr1y69fZRbVatKs6bS04G4uOxLMhAREVGxKIQQQu4iTCk5ORlqtRpJSUl6JwIsE4KCgDNngP/9D+jZU+5qiIiIyozi/P0u92NuzArH3RAREZUaw01ZwnBDRERUagw3ZYl2nA3DDRERUYkx3JQlPNcNERFRqTHclCXalpvERKAsXgOLiIioHGC4KUvUasDTU7rPrikiIqISYbgpaziomIiIqFQYbsoajrshIiIqFYabsoYtN0RERKXCcFPWcDo4ERFRqTDclDXalpvYWECjkbcWIiKicojhpqzx85OuCP70KRAfL3c1RERE5Q7DTVljbQ3Uqyfdj46WtRQiIqLyiOGmLGrcWLo9fVreOoiIiMohhpuySBtu2HJDRERUbAw3ZVFQkHTLlhsiIqJiY7gpixo1km7//ht48EDeWoiIiMoZhpuyyNERCAiQ7rP1hoiIqFgYbsoqjrshIiIqEYabsorjboiIiEqE4aas4nRwIiKiEmG4Kau04ebyZSAtTd5aiIiIyhGGm7LKy0tahADOnpW7GiIionKD4aYs46BiIiKiYmO4Kcs4qJiIiKjYGG7KMg4qJiIiKjaGm7JMG27OnQNevJC3FiIionKC4aYsq1EDcHAAMjKkWVNERET0Ugw3ZZmFRfZ1ptg1RUREVCQMN2Udx90QEREVC8NNWcdwQ0REVCwMN2VdznPdCCFrKUREROUBw01ZV7cuYG0NPHkCxMfLXQ0REVGZx3BT1tnYAPXqSffZNUVERPRSDDflAcfdEBERFRnDTXkQHCzdHj0qbx1ERETlAMNNedC6tXR76BCQmSlvLURERGUcw015UL8+4OwMpKUBp07JXQ0REVGZxnBTHlhYZLfe7N8vby1ERERlHMNNedG2rXR74IC8dRAREZVxDDflRZs20u1ffwFZWfLWQkREVIYx3JQXQUHSFcKTkoCzZ+WuhoiIqMxiuCkvrKyAVq2k++yaIiIiKhDDTXmiHXfDQcVEREQFYrgpT7Tjbg4cADQaeWshIiIqoxhuypMmTQA7O+DhQ+DiRbmrISIiKpMYbsoTa2ugZUvpPrumiIiI8sVwU95ou6YYboiIiPLFcFPe5DyZnxDy1kJERFQGMdyUN82aAUolkJgIxMbKXQ0REVGZw3BT3qhUQPPm0n12TREREeUha7g5cOAAevXqhSpVqkChUGDTpk0vfc6+ffvwyiuvQKlUIiAgABEREUavs8zhdaaIiIgKJGu4SUtLQ6NGjbB48eIibR8XF4cePXqgffv2iI6ORlhYGIYPH47t27cbudIyJufJ/DjuhoiISI9CiLLx11GhUGDjxo3o27dvgdtMmzYNf/zxB86fP69bN3DgQDx58gTbtm0r0uskJydDrVYjKSkJjo6OpS1bHk+fAmo1kJkJXL0K+PvLXREREZFRFefvd7kacxMVFYVOnTrprevSpQuioqJkqkgmdnbZ15n6/Xd5ayEiIipjylW4SUxMhKenp946T09PJCcnIz09Pd/nZGRkIDk5WW8xC6+/Lt1u2CBvHURERGVMuQo3JREeHg61Wq1bfHx85C7JMLTdd4cOSdPCiYiICEA5CzdeXl64e/eu3rq7d+/C0dERtra2+T5n+vTpSEpK0i23bt0yRanG5+MjnfNGCGDzZrmrISIiKjPKVbgJCQnB7t279dbt3LkTISEhBT5HqVTC0dFRbzEb7JoiIiLKQ9Zwk5qaiujoaERHRwOQpnpHR0fj5s2bAKRWl8GDB+u2Hz16NK5fv46pU6fi0qVLWLJkCX755Rd88MEHcpQvv9dek2737AEeP5a3FiIiojJC1nBz4sQJNG7cGI0bNwYATJo0CY0bN8bMmTMBAAkJCbqgAwB+fn74448/sHPnTjRq1Ajz5s3Djz/+iC5dushSv+xq1QLq15emhG/ZInc1REREZUKZOc+NqZjFeW5y+uQT4NNPpQHGGzfKXQ0REZFRmO15bigf2nE327YBaWny1kJERFQGMNyUdw0bAjVqAM+eSQGHiIiogmO4Ke8UCs6aIiIiyoHhxhxow82WLUBGhry1EBERyYzhxhw0bw5UrgwkJ0vTwomIiCowhhtzYGGRfc6b336TtxYiIiKZMdyYi/79pdt166QWHCIiogqK4cZctG0L1KkDpKYCK1fKXQ0REZFsGG7MhUIBjBsn3V+0CNBo5K2HiIhIJgw35uSddwAHB+DKFSDXBUaJiIgqCoYbc+LgAAwdKt1ftEjWUoiIiOTCcGNuxoyRbv/3P+DGDVlLISIikgPDjbmpXRt49VVACGDpUrmrISIiMjmGG3OkHVj8449Aerq8tRAREZkYw4056tEDqF4dePQIiIyUuxoiIiKTYrgxR5aW2WNvFi6UuqiIiIgqCIYbc/Xuu4BKBZw+DRw4IHc1REREJsNwY65cXbOnhX/0EVtviIiowmC4MWczZwJ2dsCRI8DGjXJXQ0REZBIMN+ascmVg8mTp/kcfAS9eyFsPERGRCTDcmLsPPwTc3YHYWGlqOBERkZljuDF3Dg5S9xQAzJoFpKTIWg4REZGxMdxUBCNHAv7+wL17wLx5cldDRERkVAw3FYGNDRAeLt3/z3+AxER56yEiIjIihpuK4o03gGbNgLQ0qXuKiIjITDHcVBQKBTB3rnT/+++BPXvkrYeIiMhIGG4qkjZtgFGjpPtDhwJPnshZDRERkVEw3FQ0//kPEBAA3LoFjB8vdzVEREQGx3BT0djbA6tWARYWwM8/A+vXy10RERGRQTHcVEQtWgD//Kd0f/Ro4M4deeshIiIyIIabimrmTCA4GHj0SLqCOC+sSUREZoLhpqKytpa6p1QqYPv27PPgEBERlXMMNxVZnTrAN99I9z/+GFi9WtZyiIiIDIHhpqIbNSr7yuHDhgF798pbDxERUSkx3BAwZw7Qvz/w4gXw2mvAhQtyV0RERFRiDDckTQv/6ScgNBRISgK6deMMKiIiKrcYbkiiUgGbNwOBgdIJ/rp25QU2iYioXGK4oWyursCffwJeXsC5c0CrVkBcnNxVERERFQvDDenz8wP++guoXh24dk3qqjp/Xu6qiIiIiozhhvIKCAAOHQLq1wcSEoDWrYGoKPnqycoC7t2T7/WJiKhcYbih/FWpAuzfD4SESFcP79QJ2LBBnlqmTgU8PYHdu+V5fSIiKlcYbqhgLi7Azp3S4OKnT4F+/YBJk6Qp46aSlAQsXSrdX7PGdK9LRETlFsMNFa5SJeD334EpU6Sv588H2raVZlSZwurVQHq6dH/nTl4Di4iIXorhhl7O2hqYOxfYtAlQq6XxN40bSzOrjEkI4Icfsr++dQuIjTXuaxIRUbnHcENF16cPcOoU8MorwMOHQPfuwHvvAY8fG+f1Tp4EoqMBpVJ6TUBqvSEiIioEww0VT40a0kyq8eMBhQJYvly6AOf69YbvMlq2TLp94w1pAYBduwz7GkREZHYYbqj4VCpgwQLpfDh16gB37wJvvildl+rmTcO8RmoqsHatdH/ECGm2FgDs2QNkZhrmNYiIyCwx3FDJhYYCp08DM2dK43I2bwZq1QKmTZOmj5dGZKQUcGrVAtq0kbqlnJ2B5GTg+HGDlE9EROaJ4YZKR6kEZs+WxuK0awdkZEhXGQ8IAL79Fnj+vGT71XZJjRghdX9ZWgIdO0rr2DVFRESFYLghw6hfX+oy+t//pK6qhw+BsDCgdm0pqGRkFH1f0dFS64y1NTBkSPZ6bdcUBxUTEVEhGG7IcBQKoGdP4OxZ4PvvpbMKx8UBo0ZJA5G//lrqanoZ7fTvvn0Bd/fs9a++Kt1GRQEpKQYvn4iIzAPDDRmelRUwcqR04c1vvgGqVgXu3AEmTwaqVZPG5MTE5H1eZiawbZt04j5A2kdONWpIF/bMzAQOHDD62yAiovKpTISbxYsXo3r16lCpVGjevDmOHTtW4LYRERFQKBR6i0qlMmG1VGSVKgETJ0oh58cfpXE4jx5JY3Lq1QOaNgUWL5auYTV+vHQ9q27dpEsuBAYCHTrk3ae29YZdU0REVADZw826deswadIkfPLJJzh16hQaNWqELl264F4hV4F2dHREQkKCbomPjzdhxVRsSqV0sr9Ll6SLb/buLbXunDgBjBsnDURetAi4f1/qhho3Dti+HbDI5+PJcENERC+hEELei/U0b94cTZs2xaJFiwAAGo0GPj4+GD9+PD766KM820dERCAsLAxPSjjVODk5GWq1GklJSXB0dCxN6VQa9+5J57GJiADi44EePYB//EMaNGxtXfDzHj6UApAQwO3bUmsPERGZveL8/Za15eb58+c4efIkOmlnwQCwsLBAp06dEBUVVeDzUlNTUa1aNfj4+KBPnz64cOFCgdtmZGQgOTlZb6EywMND6rI6fVrqqlq1SuqSKizYAICrKxAcLN3nlHAiIsqHrOHmwYMHyMrKgqenp956T09PJCYm5vucwMBALF++HJs3b8bPP/8MjUaDli1b4u+//853+/DwcKjVat3i4+Nj8PdBJqbtmmK4ISKifMg+5qa4QkJCMHjwYAQFBaFt27bYsGED3N3d8f333+e7/fTp05GUlKRbbt26ZeKKyeC0LX2//AJMmQIUEISJiKhikjXcuLm5wdLSEnfv3tVbf/fuXXh5eRVpH9bW1mjcuDGuXr2a7+NKpRKOjo56C5VzrVsDnTtLJwacNw+oXl2abcXgSkREkDnc2NjYIDg4GLt379at02g02L17N0JCQoq0j6ysLJw7dw6VK1c2VplU1lhbS+fD2boVCAmRQs6iRdJ5cDp0AL78UrochEYjd6VERCQD2bulJk2ahB9++AErV67ExYsX8f777yMtLQ3Dhg0DAAwePBjTp0/Xbf/pp59ix44duH79Ok6dOoW3334b8fHxGD58uFxvgeSgUEgDkA8dAnbvlqaTZ2YCe/cC06dLg449PYEBA4AlS4Dz5xl2iIgqCCu5CxgwYADu37+PmTNnIjExEUFBQdi2bZtukPHNmzdhkeN8J48fP8aIESOQmJgIZ2dnBAcH4/Dhw6hbt65cb4HkpFBIrTUdOgCxscCOHdKydy/w4IE0LueXX6RtXV2lLq2WLaUlOBjgCSCJiMyO7Oe5MTWe56aCePECOHoU2LdPOgPy4cPA06f621hbA40bS11bTZsCTZoANWvmf/JAIiKSVXH+fjPcUMXw4oU0DufAAenCm4cPA7kGsgMA1GqpRSc4WAo+r7zCwENEVAYw3BSC4YYASGc4vnFDCjpHjwLHj0snFHz2LO+2lSoBjRpJS8OG0lK/PsDPDxGRyTDcFILhhgr04gVw4UJ20Dl1Cjh7FkhPz3/7atWAunWli4Bql9q1AQcH09ZNRFQBMNwUguGGiiUzE7hyRQo7585JYefcOaCAM2IDAKpWlUJO7drS1c1r1ZIWX1/A0tJ0tRMRmRGGm0Iw3JBBPHoktfJol5gY6Ta/cTxaNjaAvz8QEKB/6+8vtQLZ2JiufiKicobhphAMN2RUjx8Dly8Dly4BFy9KrT5XrgDXrkknGyyIQgF4ewN+ftlLtWrS2ZerV5dag152UVEiIjPGcFMIhhuSRVaWdHkIbdC5dg24elVarl8veFyPloUFUKWK1LXl6wv4+GQv3t7S4uHBWV1EZLYYbgrBcENljhDAvXtAXJy0XL8OxMdLs7ni46WlsFYfLWtroHJlqZWnalUpDGlvK1fOvlWrpZYiIqJypDh/v2U/QzFRhadQSJeK8PQEWrTI+7hGI4WfW7eAmzezl7//ltb9/TeQkCDN9tI+VhiVCvDykoKOl5e0aF8/530PD2kaPIMQEZUzDDdEZZ2FRXYIado0/21evAASE4Hbt/WXO3ek4HPnjrQkJUnn8rlxQ1pextZWCjkeHoC7u/59d3fAzS371s1NmgbPMEREMmO4ITIH1tbZY3AK8/SpNKMrIUEKQwkJ0td370pfa+/fvSuNA0pPz+4aK2odrq5S0HF1zXvf1RVwcZEW7X1nZ84UIyKDYrghqkjs7LJnY71MaqrUHXb3LnD/vrTcu5d9X7s8eCDdpqdntyAlJhavrkqVsoOO9tbJSbrNuWjXOTllLyoVW4uISA/DDRHlz95eWmrUKNr2T58CDx9KYSfnbe7l0aPs5fFjaUB1Wpq03LpV/DptbKSQo1ZLS877ORdHx7z3HR2lxc6OAYnIjDDcEJFh2NlJy8u6xnLKypLGAT1+nB12tLc5lydPpEV7//Fj6XkaDfD8udSidO9eyWu3sMgOOg4O2be57+dcZ2+vv077tb09YMVfrURy4k8gEcnH0jJ7DI6/f/Geq9FIXWfa4JOUlH1b2JKSIt0mJ0uLRiMt2v0YgkqlH3Zy389vqVRJ/zb3Ona/ERUZww0RlU85W1t8fUu2DyGk7jRt0NEGn5QUacm5Xvu19n5qavZ97ZKZKe332TNpefDAsO/Xzi477ORc8ltXqZK0/cvWa1vceN0zMiMMN0RUcSkU2X/kK1cu/f4yMvRDT1qafhBKS5Pua5fc67T3c95qz16tbalKTS19nflRKvXDjjYA5fy6sMXWtvB1trZsfSKTYbghIjIUpVJaXF0Nt8+sLKl1Kb/go11yfq3dNr8l52Pa+1oZGdLy6JHhas9NoZACTs7gk/O2oHUlWVQq6XvBMFUhMdwQEZVllpbZg5YNTQip+yxn6ElPzw4/2vXp6dlf57eusG20pwjQvp52nSlow1TOwJM7AOW+n/tWez/n+tz3cy62tgxVZQDDDRFRRaVQZP8BN2RrU24vXmSHmqdP894v6Db3/aIu2ksmmjpM5ZRf8CnpolQW7b72a6VSmrFXgQMWww0RERmXtbW0mOJixULoh6lnz/KGn5zrtPcLW6cdIK59PCMje13O9TmvQ619TC4WFvphJ2cAKsrXJV1sbKRbe3vp0iwyYbghIiLzoVBIf2BtbKQTNZqKENJsufwCUGGhKPd22q+1t7nXab/Ova+MjOzZeoA0AF2uVisAaNYMOHpUntcGww0REVHpKRSmbaHKT1aWfhDKHZRyryvo69Iuz59LA8JlxHBDRERkDiwts6feV3AWchdAREREZEgMN0RERGRWGG6IiIjIrDDcEBERkVlhuCEiIiKzwnBDREREZoXhhoiIiMwKww0RERGZFYYbIiIiMisMN0RERGRWGG6IiIjIrDDcEBERkVlhuCEiIiKzwnBDREREZsVK7gJMTQgBAEhOTpa5EiIiIioq7d9t7d/xwlS4cJOSkgIA8PHxkbkSIiIiKq6UlBSo1epCt1GIokQgM6LRaHDnzh04ODhAoVCUeD/Jycnw8fHBrVu34OjoaMAKKTcea9PhsTYtHm/T4bE2HWMdayEEUlJSUKVKFVhYFD6qpsK13FhYWMDb29tg+3N0dOQPionwWJsOj7Vp8XibDo+16RjjWL+sxUaLA4qJiIjIrDDcEBERkVlhuCkhpVKJTz75BEqlUu5SzB6PtenwWJsWj7fp8FibTlk41hVuQDERERGZN7bcEBERkVlhuCEiIiKzwnBDREREZoXhhoiIiMwKw00JLV68GNWrV4dKpULz5s1x7NgxuUsqV8LDw9G0aVM4ODjAw8MDffv2xeXLl/W2efbsGcaOHQtXV1fY29ujX79+uHv3rt42N2/eRI8ePWBnZwcPDw98+OGHyMzMNOVbKXe+/PJLKBQKhIWF6dbxWBvO7du38fbbb8PV1RW2trZo0KABTpw4oXtcCIGZM2eicuXKsLW1RadOnRAbG6u3j0ePHmHQoEFwdHSEk5MT3nvvPaSmppr6rZRpWVlZmDFjBvz8/GBrawt/f3989tlnetcd4rEuuQMHDqBXr16oUqUKFAoFNm3apPe4oY7t2bNn0bp1a6hUKvj4+GDOnDmGeQOCii0yMlLY2NiI5cuXiwsXLogRI0YIJycncffuXblLKze6dOkiVqxYIc6fPy+io6NF9+7dha+vr0hNTdVtM3r0aOHj4yN2794tTpw4IVq0aCFatmypezwzM1PUr19fdOrUSZw+fVps3bpVuLm5ienTp8vxlsqFY8eOierVq4uGDRuKiRMn6tbzWBvGo0ePRLVq1cTQoUPF0aNHxfXr18X27dvF1atXddt8+eWXQq1Wi02bNokzZ86I3r17Cz8/P5Genq7bpmvXrqJRo0biyJEj4q+//hIBAQHirbfekuMtlVlffPGFcHV1FVu2bBFxcXFi/fr1wt7eXnz77be6bXisS27r1q3i448/Fhs2bBAAxMaNG/UeN8SxTUpKEp6enmLQoEHi/PnzYu3atcLW1lZ8//33pa6f4aYEmjVrJsaOHav7OisrS1SpUkWEh4fLWFX5du/ePQFA7N+/XwghxJMnT4S1tbVYv369bpuLFy8KACIqKkoIIf3wWVhYiMTERN02S5cuFY6OjiIjI8O0b6AcSElJETVr1hQ7d+4Ubdu21YUbHmvDmTZtmmjVqlWBj2s0GuHl5SXmzp2rW/fkyROhVCrF2rVrhRBCxMTECADi+PHjum3+/PNPoVAoxO3bt41XfDnTo0cP8e677+qte/3118WgQYOEEDzWhpQ73Bjq2C5ZskQ4Ozvr/Q6ZNm2aCAwMLHXN7JYqpufPn+PkyZPo1KmTbp2FhQU6deqEqKgoGSsr35KSkgAALi4uAICTJ0/ixYsXese5du3a8PX11R3nqKgoNGjQAJ6enrptunTpguTkZFy4cMGE1ZcPY8eORY8ePfSOKcBjbUi///47mjRpgv79+8PDwwONGzfGDz/8oHs8Li4OiYmJesdarVajefPmesfayckJTZo00W3TqVMnWFhY4OjRo6Z7M2Vcy5YtsXv3bly5cgUAcObMGRw8eBDdunUDwGNtTIY6tlFRUWjTpg1sbGx023Tp0gWXL1/G48ePS1VjhbtwZmk9ePAAWVlZer/kAcDT0xOXLl2SqaryTaPRICwsDKGhoahfvz4AIDExETY2NnByctLb1tPTE4mJibpt8vs+aB+jbJGRkTh16hSOHz+e5zEea8O5fv06li5dikmTJuGf//wnjh8/jgkTJsDGxgZDhgzRHav8jmXOY+3h4aH3uJWVFVxcXHisc/joo4+QnJyM2rVrw9LSEllZWfjiiy8waNAgAOCxNiJDHdvExET4+fnl2Yf2MWdn5xLXyHBDshs7dizOnz+PgwcPyl2KWbp16xYmTpyInTt3QqVSyV2OWdNoNGjSpAn+/e9/AwAaN26M8+fP47vvvsOQIUNkrs68/PLLL1i9ejXWrFmDevXqITo6GmFhYahSpQqPNXG2VHG5ubnB0tIyz0ySu3fvwsvLS6aqyq9x48Zhy5Yt2Lt3L7y9vXXrvby88Pz5czx58kRv+5zH2cvLK9/vg/Yxkpw8eRL37t3DK6+8AisrK1hZWWH//v1YsGABrKys4OnpyWNtIJUrV0bdunX11tWpUwc3b94EkH2sCvv94eXlhXv37uk9npmZiUePHvFY5/Dhhx/io48+wsCBA9GgQQO88847+OCDDxAeHg6Ax9qYDHVsjfl7heGmmGxsbBAcHIzdu3fr1mk0GuzevRshISEyVla+CCEwbtw4bNy4EXv27MnTNBkcHAxra2u943z58mXcvHlTd5xDQkJw7tw5vR+gnTt3wtHRMc8fmIqsY8eOOHfuHKKjo3VLkyZNMGjQIN19HmvDCA0NzXNKgytXrqBatWoAAD8/P3h5eekd6+TkZBw9elTvWD958gQnT57UbbNnzx5oNBo0b97cBO+ifHj69CksLPT/hFlaWkKj0QDgsTYmQx3bkJAQHDhwAC9evNBts3PnTgQGBpaqSwoAp4KXRGRkpFAqlSIiIkLExMSIkSNHCicnJ72ZJFS4999/X6jVarFv3z6RkJCgW54+farbZvTo0cLX11fs2bNHnDhxQoSEhIiQkBDd49rpyZ07dxbR0dFi27Ztwt3dndOTiyDnbCkheKwN5dixY8LKykp88cUXIjY2VqxevVrY2dmJn3/+WbfNl19+KZycnMTmzZvF2bNnRZ8+ffKdQtu4cWNx9OhRcfDgQVGzZk1OT85lyJAhomrVqrqp4Bs2bBBubm5i6tSpum14rEsuJSVFnD59Wpw+fVoAEF9//bU4ffq0iI+PF0IY5tg+efJEeHp6infeeUecP39eREZGCjs7O04Fl9PChQuFr6+vsLGxEc2aNRNHjhyRu6RyBUC+y4oVK3TbpKenizFjxghnZ2dhZ2cnXnvtNZGQkKC3nxs3bohu3boJW1tb4ebmJiZPnixevHhh4ndT/uQONzzWhvO///1P1K9fXyiVSlG7dm2xbNkyvcc1Go2YMWOG8PT0FEqlUnTs2FFcvnxZb5uHDx+Kt956S9jb2wtHR0cxbNgwkZKSYsq3UeYlJyeLiRMnCl9fX6FSqUSNGjXExx9/rDetmMe65Pbu3Zvv7+ghQ4YIIQx3bM+cOSNatWollEqlqFq1qvjyyy8NUr9CiByncyQiIiIq5zjmhoiIiMwKww0RERGZFYYbIiIiMisMN0RERGRWGG6IiIjIrDDcEBERkVlhuCEiIiKzwnBDREbVrl07hIWFyV2GHoVCgU2bNsldBhEZCU/iR0RG9ejRI1hbW8PBwQHVq1dHWFiYycLOrFmzsGnTJkRHR+utT0xMhLOzM5RKpUnqICLTspK7ACIyby4uLgbf5/Pnz2FjY1Pi5/OKz0Tmjd1SRGRU2m6pdu3aIT4+Hh988AEUCgUUCoVum4MHD6J169awtbWFj48PJkyYgLS0NN3j1atXx2effYbBgwfD0dERI0eOBABMmzYNtWrVgp2dHWrUqIEZM2borjAcERGB2bNn48yZM7rXi4iIAJC3W+rcuXPo0KEDbG1t4erqipEjRyI1NVX3+NChQ9G3b1/85z//QeXKleHq6oqxY8fqXc2YiMoOhhsiMokNGzbA29sbn376KRISEpCQkAAAuHbtGrp27Yp+/frh7NmzWLduHQ4ePIhx48bpPf8///kPGjVqhNOnT2PGjBkAAAcHB0RERCAmJgbffvstfvjhB8yfPx8AMGDAAEyePBn16tXTvd6AAQPy1JWWloYuXbrA2dkZx48fx/r167Fr1648r793715cu3YNe/fuxcqVKxEREaELS0RUtrBbiohMwsXFBZaWlnBwcNDrFgoPD8egQYN043Bq1qyJBQsWoG3btli6dClUKhUAoEOHDpg8ebLePv/1r3/p7levXh1TpkxBZGQkpk6dCltbW9jb28PKyqrQbqg1a9bg2bNn+Omnn1CpUiUAwKJFi9CrVy989dVX8PT0BAA4Oztj0aJFsLS0RO3atdGjRw/s3r0bI0aMMMjxISLDYbghIlmdOXMGZ8+exerVq3XrhBDQaDSIi4tDnTp1AABNmjTJ89x169ZhwYIFuHbtGlJTU5GZmQlHR8divf7FixfRqFEjXbABgNDQUGg0Gly+fFkXburVqwdLS0vdNpUrV8a5c+eK9VpEZBoMN0Qkq9TUVIwaNQoTJkzI85ivr6/ufs7wAQBRUVEYNGgQZs+ejS5dukCtViMyMhLz5s0zSp3W1tZ6XysUCmg0GqO8FhGVDsMNEZmMjY0NsrKy9Na98soriImJQUBAQLH2dfjwYVSrVg0ff/yxbl18fPxLXy+3OnXqICIiAmlpaboAdejQIVhYWCAwMLBYNRFR2cABxURkMtWrV8eBAwdw+/ZtPHjwAIA04+nw4cMYN24coqOjERsbi82bN+cZ0JtbzZo1cfPmTURGRuLatWtYsGABNm7cmOf14uLiEB0djQcPHiAjIyPPfgYNGgSVSoUhQ4bg/Pnz2Lt3L8aPH4933nlH1yVFROULww0Rmcynn36KGzduwN/fH+7u7gCAhg0bYv/+/bhy5Qpat26Nxo0bY+bMmahSpUqh++rduzc++OADjBs3DkFBQTh8+LBuFpVWv3790LVrV7Rv3x7u7u5Yu3Ztnv3Y2dlh+/btePToEZo2bYo33ngDHTt2xKJFiwz3xonIpHiGYiIiIjIrbLkhIiIis8JwQ0RERGaF4YaIiIjMCsMNERERmRWGGyIiIjIrDDdERERkVhhuiIiIyKww3BAREZFZYbghIiIis8JwQ0RERGaF4YaIiIjMCsMNERERmZX/AwgvC8AAgReLAAAAAElFTkSuQmCC\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# predicting probabilities of being in different classes  with the optimal weight vectors.\n",
        "# This is for training dataset.\n",
        "y_train_pred = prediction(X_train, n_layer, f_list, list_w, list_b)   # calling prediction function to compute prediction on training dataset.\n",
        "print(f'The sum of the probabilities of being in different classes of a data sample is: {np.sum(y_train_pred[0])}')\n",
        "print('The prediction of probabilities of being in different classes of each data sample is:')\n",
        "print(y_train_pred)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_uK7WT5Yfp5k",
        "outputId": "ad5c0e57-3e47-4753-c357-2d4f9379d30f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The sum of the probabilities of being in different classes of a data sample is: 1.0000000000000002\n",
            "The prediction of probabilities of being in different classes of each data sample is:\n",
            "[[3.81325339e-03 6.29365113e-07 1.03452167e-03 ... 4.05507392e-04\n",
            "  1.37744309e-03 1.16463444e-04]\n",
            " [9.99364707e-01 1.00254332e-12 2.50307724e-04 ... 1.35268444e-06\n",
            "  7.13190995e-06 7.13035813e-06]\n",
            " [1.56361110e-04 9.15797130e-05 2.10528865e-03 ... 2.49660088e-02\n",
            "  1.37276477e-03 6.52603501e-02]\n",
            " ...\n",
            " [5.15195800e-05 2.13383645e-06 3.05984248e-06 ... 2.18188198e-05\n",
            "  2.85666043e-03 9.65828559e-04]\n",
            " [2.27187998e-02 5.33019961e-08 1.26234372e-02 ... 5.26712003e-04\n",
            "  2.14902581e-04 3.05100858e-03]\n",
            " [1.07175516e-01 2.19465532e-05 1.22541772e-02 ... 1.77762330e-04\n",
            "  8.36973006e-01 1.31209607e-02]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# finding label based on predicted value.\n",
        "\n",
        "labeled_y_train = find_label(y_train_pred)    # calling find_label function to find corresponding label.\n",
        "print(f'The predicted label for training dataset is:')\n",
        "print(labeled_y_train)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7Sw_KQLKfpy2",
        "outputId": "2ffc8edc-9ec1-4ff3-a2c2-5ea47539581e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The predicted label for training dataset is:\n",
            "[[0. 0. 0. ... 0. 0. 0.]\n",
            " [1. 0. 0. ... 0. 0. 0.]\n",
            " [0. 0. 0. ... 0. 0. 0.]\n",
            " ...\n",
            " [0. 0. 0. ... 0. 0. 0.]\n",
            " [0. 0. 0. ... 0. 0. 0.]\n",
            " [0. 0. 0. ... 0. 1. 0.]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#printing the actual label of training dataset.\n",
        "\n",
        "print('The actual label of training dataset:')\n",
        "print(y_train)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VANr9LDQfptZ",
        "outputId": "e92de5fd-1cf7-4fd2-8865-7625f73ce7fa"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The actual label of training dataset:\n",
            "[[0 0 0 ... 0 0 0]\n",
            " [1 0 0 ... 0 0 0]\n",
            " [0 0 0 ... 0 0 0]\n",
            " ...\n",
            " [0 0 0 ... 0 0 0]\n",
            " [0 0 0 ... 0 0 0]\n",
            " [0 0 0 ... 0 1 0]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "accurate1 = accu(y_train, labeled_y_train)   # calling accuracy function to compute accuracy\n",
        "print(f'The training accuracy is: {accurate1}')      # predicted label and actual lebel.\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_CI2R5njfpnb",
        "outputId": "f27422b2-8009-46aa-f300-b25ec4627cfe"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The training accuracy is: 0.9225\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# predicting probabilities of being in different classes  with the optimal weight vectors.\n",
        "# This is for testing dataset.\n",
        "\n",
        "y_pred = prediction(X_test, n_layer, f_list, list_w, list_b)  # calling prediction function to compute prediction on testing dataset.\n",
        "print(f'The sum of the probabilities of being in different classes of a data sample is: {np.sum(y_pred[0])}')\n",
        "print('The prediction of probabilities of being in different classes of each data sample is:')\n",
        "print(y_pred)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mJnRxi5ifph_",
        "outputId": "91f27cd8-f598-4e6a-ffd7-a1b605d56741"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The sum of the probabilities of being in different classes of a data sample is: 1.0\n",
            "The prediction of probabilities of being in different classes of each data sample is:\n",
            "[[4.75014425e-05 5.12637453e-07 2.16741287e-03 ... 9.95421177e-01\n",
            "  3.26845911e-06 1.14217699e-03]\n",
            " [8.34031878e-04 2.15401834e-06 9.97212795e-01 ... 2.73667796e-08\n",
            "  1.10451073e-04 2.29073448e-12]\n",
            " [4.99920533e-07 9.80861974e-01 4.83464599e-03 ... 3.07340986e-03\n",
            "  4.46065250e-03 1.05570753e-04]\n",
            " ...\n",
            " [3.26821308e-08 2.18302410e-07 8.85743915e-06 ... 1.82410925e-04\n",
            "  6.73748153e-04 2.48577113e-02]\n",
            " [7.52707695e-05 6.34605029e-05 4.79749097e-05 ... 4.05990523e-07\n",
            "  4.19548635e-02 3.72331609e-05]\n",
            " [9.08278959e-06 3.47790113e-14 3.31376791e-04 ... 7.50951582e-10\n",
            "  2.20292635e-08 2.11641883e-09]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# finding label based on predicted value.\n",
        "\n",
        "labeled_y = find_label(y_pred)    # calling find_label function to find corresponding label.\n",
        "print(f'The predicted label for training dataset is:')\n",
        "print(labeled_y)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RWoyafVFfpa9",
        "outputId": "6052f32d-3b63-45f1-8283-8ce658743a3e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The predicted label for training dataset is:\n",
            "[[0. 0. 0. ... 1. 0. 0.]\n",
            " [0. 0. 1. ... 0. 0. 0.]\n",
            " [0. 1. 0. ... 0. 0. 0.]\n",
            " ...\n",
            " [0. 0. 0. ... 0. 0. 0.]\n",
            " [0. 0. 0. ... 0. 0. 0.]\n",
            " [0. 0. 0. ... 0. 0. 0.]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#printing the actual label of testing dataset.\n",
        "\n",
        "print('The actual label of testing dataset:')\n",
        "print(y_test)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bTzwv59yfpUS",
        "outputId": "24053037-0249-4f85-90a7-d8aa1192e905"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The actual label of testing dataset:\n",
            "[[0 0 0 ... 1 0 0]\n",
            " [0 0 1 ... 0 0 0]\n",
            " [0 1 0 ... 0 0 0]\n",
            " ...\n",
            " [0 0 0 ... 0 0 0]\n",
            " [0 0 0 ... 0 0 0]\n",
            " [0 0 0 ... 0 0 0]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "accurate = accu(y_test, labeled_y)           # calling accuracy function to compute accuracy\n",
        "print(f'The testing accuracy is: {accurate}')      # predicted label and actual lebel.\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "s5P2ojWkfpL-",
        "outputId": "d1939c07-239e-4a1f-8460-3f72eee69ecb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The testing accuracy is: 0.9226\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "dsVe9qdtfpDf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Question :- How much improvement does the larger network provide?\n",
        "\n",
        "#Answer :- The larger network provides around 4 - 5 % improvement."
      ],
      "metadata": {
        "id": "Rf3iYb2m0Xjx"
      }
    }
  ]
}